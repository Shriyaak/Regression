{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f13867-683d-422e-a09d-84edb8918848",
   "metadata": {},
   "source": [
    "# REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3279c-45bd-40bc-a5c5-c6b538301b5d",
   "metadata": {},
   "source": [
    "Regression models (both linear and non linear) are used for predicting a continious real value , like salary for example )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf15b8-c1de-4300-afc6-3477143bc430",
   "metadata": {},
   "source": [
    "## SIMPLE LINEAR REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3173c-9353-4810-be09-529d3e10a417",
   "metadata": {},
   "source": [
    "### Assumptions of linear regression models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab24fc79-ba01-4cb3-ac2b-330a07d0ac3b",
   "metadata": {},
   "source": [
    "1. Linearity: The relationship between predictors and response variables is linear \n",
    "2. Independence: Observations are independent of each other \n",
    "3. Homoscedasticity: The variance of residuals is constant across all levels of predictors \n",
    "4. Normality of errors: The residual errors are normally distributed \n",
    "5. No Multi-collinearity: Predictors are not highly co-related"
   ]
  },
  {
   "cell_type": "raw",
   "id": "792d2d11-b6b9-46f8-bb5e-b4fe83d827da",
   "metadata": {},
   "source": [
    "(only one feature)\n",
    "\n",
    "y = β0 +β1 x1 +ϵ ;\n",
    "\n",
    "where, \n",
    "y = dependent variable(response) ;\n",
    "x1 = independent variable(predictors) ; \n",
    "β0,β1= coefficients to be estimated ;\n",
    "ϵ = Random error terms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffc4507d-b968-4e1c-a96a-2f5aeaad3059",
   "metadata": {},
   "source": [
    "OLS( Ordinary Least square method) finds the values of β0 , β1 that minimises the sum of squared errors(SSE): \n",
    "\n",
    "SSE = i=1∑n { (yi −y^ i ) }^ 2\n",
    "\n",
    "where, \n",
    "yi = actual value of the response variables ;\n",
    "y^ i = Predicted values (y^ I = β0 + β1xi1 + … βpxip) \n",
    "The best fit line is such that the sum of the squares of the residuals is minimised"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eec3f262-d27e-4e29-bcd6-2814f5041e19",
   "metadata": {},
   "source": [
    "DATA: \n",
    "YearsExperience(X1) = independent variable/ predictor (1 feature) \n",
    "Salary(y) = dependent variable / response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcb8b2f-1eda-4883-a4c5-25574acfdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22235c2b-7cd5-4b4e-a3ed-5205970f3cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5 10.3  4.1  3.9  9.5  8.7]\n",
      "[ 9.6  4.   5.3  7.9  2.9  5.1  3.2  4.5  8.2  6.8  1.3 10.5  3.   2.2\n",
      "  5.9  6.   3.7  3.2  9.   2.   1.1  7.1  4.9  4. ]\n"
     ]
    }
   ],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0) \n",
    "print(X_test.flatten())\n",
    "print(X_train.flatten()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4c4fbd-25a0-4179-9f84-e9c7cb977724",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Simple_Reg_data.csv')\n",
    "X = dataset.iloc[:,0].values.reshape(-1,1) #reshaping to 2D array \n",
    "y = dataset.iloc[:,1].values     #target remains 1D \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3854df77-4914-41f4-8a43-e13be7d4f1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAINING THE SIMPLE REGRESSION MODEL ON THE TRAINING SET \n",
    "from sklearn.linear_model import LinearRegression \n",
    "regressor = LinearRegression()\n",
    "#the method that we are going to use to train our regression model is the fit methd \n",
    "regressor.fit(X_train, y_train)  #fit is the method of LinearRegression class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233f790f-5eb5-4f21-8644-709912a344f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTING THE TEST SET RESULT \n",
    "y_pred_test = regressor.predict(X_test) \n",
    "y_pred_train = regressor.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f1bbac-2b5a-49b5-8acb-f701e9baa86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHFCAYAAAAwv7dvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABln0lEQVR4nO3deVxU5f4H8M+AMCzCCCrgCIpbLqG5lUsi7lpiGllukdZtvaKSVuZtUdtMLdP0qlneblqKpehVf+aS4pa4pOJebiiI4II4KMo2fH9/TIwcZlCWYWaAz/v1mhfOc54553uGZb5+n+c8RyUiAiIiIiIqMwdbB0BERERUWTCxIiIiIrIQJlZEREREFsLEioiIiMhCmFgRERERWQgTKyIiIiILYWJFREREZCFMrIiIiIgshIkVERERkYUwsaIK77///S9UKlWRj+3bt9s6xPvavn17hYjzQfLPY+XKlbYOpUTyf34uXLjwwL6bNm1Cnz59oNVqoVarodVq0a1bN3z++eelOvaoUaMQGBhYqtfeT7du3dCtWzeL77egc+fOQa1WIzY21vi9L86jrMpyblOmTLFIDLa2YcMGTJkyxaQ9JycHjRo1wuzZs60eE91TzdYBEFnK999/j2bNmpm0t2jRwgbRFF/btm0RGxtr93FWdQsXLsQbb7yBZ555BvPmzYO3tzcSExOxZ88erFy5Eu+++66tQzSaP39+uR/jrbfeQu/evdGpUyekp6cjNjZWsf3pp59Go0aN8MUXX1j0uGU5t5dffhn9+vWzYDS2sWHDBvz73/82Sa6cnJzw4Ycf4s0330R4eDhq1qxpmwCrOCZWVGkEBQWhffv2tg6j2HJycqBSqeDp6YmOHTvaOhx6gGnTpqFr164mFbnw8HDk5eXZKCqlO3fuwM3NrdyT9FOnTmHNmjXYuHEjAJj9GVar1ahRo8Z9f7ZFBJmZmXB1dS32sctybv7+/vD39y/16yuCYcOGYfz48fjmm2/wr3/9y9bhVEkcCqQqIyoqCiqVCvPmzVO0T548GY6OjtiyZQsA4MKFC1CpVJgxYwY+/fRT1KtXDy4uLmjfvj22bt1qst8zZ85g+PDh8PHxgVqtRvPmzfHvf/9b0Sd/qGTp0qWYMGEC6tatC7VajbNnzxY5FPjHH3/gqaeegre3N1xcXNCmTRv8/PPPij75w1gxMTF44403UKtWLdSsWRNhYWG4fPmySazLli1Dp06dUL16dVSvXh2tW7fG4sWLFX1+++039OzZE56ennBzc8Pjjz9u9ryLkpmZifHjx8PPzw+urq4ICQnB4cOHTc5t6NChCAwMhKurKwIDAzFs2DBcvHhR0e/OnTt466230KBBA7i4uMDb2xvt27fH8uXLS/xeAcDevXvx+OOPw8XFBVqtFpMmTUJOTk6xzis1NRV16tQxu83BQfmn9N///je6du0KHx8fuLu7o2XLlpgxY0axjlXc13br1g1BQUHYuXMnOnfuDDc3N7z00kvGbYWHy7Kzs/HJJ5+gWbNmUKvVqF27Nl588UVcu3ZN0W/btm3o1q0batasCVdXV9SrVw/PPPMM7ty5Y+yzYMEC+Pn5oXfv3g88n4JUKhUiIiKwcOFCNG/eHGq1Gj/88AMAYOrUqejQoQO8vb3h6emJtm3bYvHixRARk/MueG75v69ffPEFZs2ahQYNGqB69ero1KkT9u7dq3ituaHAwMBAhIaGYuPGjWjbti1cXV3RrFkz/Oc//zGJf/fu3ejUqRNcXFxQt25dfPDBB/juu++KNZR8/vx5DB061DiM7Ovri549eyIuLk7Rb8WKFejUqRPc3d1RvXp19O3bV/H7M2rUKOPfl4JDrPnHd3Z2xpAhQ7Bo0SKT946sRIgquO+//14AyN69eyUnJ0fxyM3NVfR9/fXXxdnZWQ4cOCAiIlu3bhUHBwd5//33jX3i4+MFgAQEBEiXLl1k1apV8ssvv8ijjz4qTk5OsmfPHmPfEydOiEajkZYtW8qSJUtk8+bNMmHCBHFwcJApU6YY+8XExAgAqVu3rgwePFjWrl0r69evl9TUVOO2mJgYY/9t27aJs7OzBAcHy4oVK2Tjxo0yatQoASDff/+9ybk3bNhQxowZI5s2bZLvvvtOvLy8pHv37opz/+CDDwSAhIWFyS+//CKbN2+WWbNmyQcffGDss3TpUlGpVDJo0CCJjo6WdevWSWhoqDg6Ospvv/123+9D/nkEBATIwIEDZd26dfLjjz9K48aNxdPTU86dO2fs+8svv8iHH34oq1evlh07dkhUVJSEhIRI7dq15dq1a8Z+r732mri5ucmsWbMkJiZG1q9fL59//rnMnTu3xO/ViRMnxM3NTVq0aCHLly+X//3vf9K3b1+pV6+eAJD4+Pj7nl+vXr2kWrVqMnnyZImLizP52SrozTfflAULFsjGjRtl27Zt8tVXX0mtWrXkxRdfVPQbOXKk1K9fv1SvDQkJEW9vbwkICJC5c+dKTEyM7Nixw7gtJCTE2Fev10u/fv3E3d1dpk6dKlu2bJHvvvtO6tatKy1atJA7d+6IiOFn38XFRXr37i1r1qyR7du3y08//STh4eGSlpZm3F/Dhg3lueeeu+/7Vb9+fenfv7+iLf93oFWrVrJs2TLZtm2bHD9+XERERo0aJYsXL5YtW7bIli1b5OOPPxZXV1eZOnWqyXkXPLf839fAwEDp16+frFmzRtasWSMtW7YULy8vuXnzprHv5MmTpfDHXv369cXf319atGghS5YskU2bNsmzzz4rAIzvp4jIkSNHxMXFRVq1aiVRUVGydu1aefLJJyUwMLBYPz9NmzaVxo0by9KlS2XHjh2yatUqmTBhguL3/tNPPxWVSiUvvfSSrF+/XqKjo6VTp07i7u4uJ06cEBGRs2fPyuDBgwWAxMbGGh+ZmZnG/axYsUIAyNGjR+8bE5UPJlZU4eUnF+Yejo6Oir6ZmZnSpk0badCggZw8eVJ8fX0lJCRE8SGZ/4daq9XK3bt3je3p6eni7e0tvXr1Mrb17dtX/P39RafTKY4TEREhLi4ucuPGDRG5l3R07drVJH5ziVWzZs2kTZs2kpOTo+gbGhoqderUEb1erzj3f/7zn4p+M2bMEACSnJwsIiLnz58XR0dHGTFiRJHvY0ZGhnh7e8uAAQMU7Xq9Xh555BF57LHHinxtwfNo27at5OXlGdsvXLggTk5O8vLLLxf52tzcXLl9+7a4u7vLnDlzjO1BQUEyaNCg+x63uO/VkCFDxNXVVVJSUhTHbdasWbE+GM+ePStBQUHGny1XV1fp2bOnzJs3T7Kzs4t8nV6vl5ycHFmyZIk4OjoafyZEzCdWxX1tSEiIAJCtW7eavK5w8rF8+XIBIKtWrVL0O3DggACQ+fPni4jIypUrBYDExcUVGdOVK1cEgHz++edF9hEpOrHSaDSK8zAn/7w/+ugjqVmzpuLnqajEqmXLlorf4/379wsAWb58ubGtqMTKxcVFLl68aGy7e/eueHt7y2uvvWZse/bZZ8Xd3V2R+Ov1emnRosUDf36uX78uAGT27NlF9klISJBq1arJmDFjFO23bt0SPz8/RSI7evRok/Mo6MyZMwJAFixYUGQfKj8cCqRKY8mSJThw4IDisW/fPkUftVqNn3/+GampqWjbti1EBMuXL4ejo6PJ/sLCwuDi4mJ87uHhgQEDBmDnzp3Q6/XIzMzE1q1b8fTTT8PNzQ25ubnGx5NPPonMzEyToYhnnnnmgedx9uxZ/PnnnxgxYgQAmOw3OTkZf/31l+I1Tz31lOJ5q1atAMA4tLZlyxbo9XqMHj26yOPu2bMHN27cwMiRIxXHzMvLQ79+/XDgwAFkZGQ8MP7hw4crhlvq16+Pzp07IyYmxth2+/ZtTJw4EY0bN0a1atVQrVo1VK9eHRkZGTh16pSx32OPPYZff/0V7777LrZv3467d++W+r2KiYlBz5494evra3y9o6MjhgwZ8sBzAoBGjRrhyJEj2LFjB6ZOnYpevXrhwIEDiIiIQKdOnZCZmWnse/jwYTz11FOoWbMmHB0d4eTkhBdeeAF6vR6nT5++73FK8lovLy/06NHjgbGvX78eNWrUwIABAxTvUevWreHn52cchm7dujWcnZ3x6quv4ocffsD58+dN9pU/xOzj4/PA45rTo0cPeHl5mbRv27YNvXr1gkajMZ73hx9+iNTUVFy9evWB++3fv7/i97jw78D9tG7dGvXq1TM+d3FxwUMPPaR47Y4dO9CjRw/UqlXL2Obg4IDnnnvugfv39vZGo0aNMHPmTMyaNQuHDx82mZe3adMm5Obm4oUXXlB8j1xcXBASElKiq4bzvzdJSUnFfg1ZDhMrqjSaN2+O9u3bKx7t2rUz6de4cWMEBwcjMzMTI0aMKHLejJ+fn9m27Oxs3L59G6mpqcjNzcXcuXPh5OSkeDz55JMAgOvXryteX9SxCrpy5QoAw1VXhff7z3/+0+x+C1/9o1arAcCYiOTPo7nfxN384w4ePNjkuNOnT4eI4MaNGw+Mv6j3LTU11fh8+PDhmDdvHl5++WVs2rQJ+/fvx4EDB1C7dm1F8vT1119j4sSJWLNmDbp37w5vb28MGjQIZ86cKfF7lZqaWmRsxeXg4ICuXbviww8/xNq1a3H58mUMGTIEBw8eNM7JSUhIQHBwMJKSkjBnzhzs2rULBw4cMM6LKZwcFlTS1xbn5wkwvE83b96Es7OzyfuUkpJifI8aNWqE3377DT4+Phg9ejQaNWqERo0aYc6cOcZ95cdQ8D8dJWEu5v3796NPnz4AgG+//Ra///47Dhw4gPfee09xzPt50O9ASV6b//qCr01NTVUk5fnMtRWmUqmwdetW9O3bFzNmzEDbtm1Ru3ZtjB07Frdu3QJw72f50UcfNfkerVixwuR3/n7yvzfFOXeyPF4VSFXOd999h//7v//DY489hnnz5mHIkCHo0KGDSb+UlBSzbc7OzqhevTqcnJzg6OiI8PDwIitBDRo0UDwvzho6+f8jnjRpEsLCwsz2adq06QP3U1Dt2rUBAJcuXUJAQMB9jzt37twir+QqzodIUe9b/oeXTqfD+vXrMXnyZMUSBVlZWSaJm7u7O6ZOnYqpU6fiypUrxurVgAED8Oeff5bovapZs2aRsZWWu7s7Jk2ahBUrVuD48eMAgDVr1iAjIwPR0dGoX7++sW/hScrmlPS1xV2TKf+ihvyr+Arz8PAw/js4OBjBwcHQ6/X4448/MHfuXERGRsLX1xdDhw41vufFSbKLG3NUVBScnJywfv16RcK2Zs2aUh2jPNSsWdOY/BRU3J+f+vXrGy8UOX36NH7++WdMmTIF2dnZWLhwofF9XblypeJ7Xxr535uC1TWyHiZWVKUcO3YMY8eOxQsvvIBvv/0WnTt3xpAhQ3D48GGT4Yno6GjMnDnT+If+1q1bWLduHYKDg+Ho6Ag3Nzd0794dhw8fRqtWreDs7GyRGJs2bYomTZrgyJEj+Oyzzyyyzz59+sDR0RELFixAp06dzPZ5/PHHUaNGDZw8eRIRERGlPtby5csxfvx44wfoxYsXsWfPHrzwwgsADB+sImKsKOT77rvvoNfri9yvr68vRo0ahSNHjmD27Nm4c+dOid6r7t27Y+3atbhy5YoxQdTr9VixYkWxzis5OdlstSV/6FKr1RrPD4Di/EQE33777QOPUZbX3k9oaCiioqKg1+vN/ifCHEdHR3To0AHNmjXDTz/9hEOHDmHo0KGoX78+XF1dce7cuTLFVJBKpUK1atUUQ3l3797F0qVLLXaMsgoJCcGGDRtw/fp1Y8KSl5eHX375pcT7euihh/D+++9j1apVOHToEACgb9++qFatGs6dO/fAKQMFq3HmlqrIH8Ll2ni2wcSKKo3jx48jNzfXpL1Ro0aoXbs2MjIy8Nxzz6FBgwaYP38+nJ2d8fPPP6Nt27Z48cUXTf537OjoiN69e2P8+PHIy8vD9OnTkZ6ejqlTpxr7zJkzB126dEFwcDDeeOMNBAYG4tatWzh79izWrVuHbdu2lepcvvnmGzzxxBPo27cvRo0ahbp16+LGjRs4deoUDh06VOI/5oGBgfjXv/6Fjz/+GHfv3sWwYcOg0Whw8uRJXL9+HVOnTkX16tUxd+5cjBw5Ejdu3MDgwYPh4+ODa9eu4ciRI7h27RoWLFjwwGNdvXoVTz/9NF555RXodDpMnjwZLi4umDRpEgDDmkddu3bFzJkzUatWLQQGBmLHjh1YvHgxatSoodhXhw4dEBoailatWsHLywunTp3C0qVL0alTJ7i5uZXovXr//fexdu1a9OjRAx9++CHc3Nzw73//u1jzxgDg4YcfRs+ePfHEE0+gUaNGyMzMxL59+/Dll1/C19cX//jHPwAAvXv3hrOzM4YNG4Z33nkHmZmZWLBgAdLS0h54jLK89n6GDh2Kn376CU8++STGjRuHxx57DE5OTrh06RJiYmIwcOBAPP3001i4cCG2bduG/v37o169esjMzDQOcfbq1QuA4XJ+c0sZlEX//v0xa9YsDB8+HK+++ipSU1PxxRdfmCTftvTee+9h3bp16NmzJ9577z24urpi4cKFxp+fwktuFHT06FFERETg2WefRZMmTeDs7Ixt27bh6NGjxqptYGAgPvroI7z33ns4f/48+vXrBy8vL1y5cgX79+83Vm8BoGXLlgCA6dOn44knnoCjo6PiP3d79+6Fo6MjunbtWp5vCRXFplPniSzgflcFApBvv/1WRESef/55cXNzM162nO+XX34RAPLVV1+JyL2rjKZPny5Tp04Vf39/cXZ2ljZt2simTZtMjh8fHy8vvfSS1K1bV5ycnKR27drSuXNn+eSTT4x98q+Y++WXX0xeb+6qQBHD5d3PPfec+Pj4iJOTk/j5+UmPHj1k4cKFJueev3zEg/a5ZMkSefTRR8XFxUWqV68ubdq0USxJICKyY8cO6d+/v3h7e4uTk5PUrVtX+vfvbzZ2c8dcunSpjB07VmrXri1qtVqCg4Pljz/+UPS9dOmSPPPMM+Ll5SUeHh7Sr18/OX78uNSvX19Gjhxp7Pfuu+9K+/btxcvLS9RqtTRs2FDefPNNuX79eonfKxGR33//XTp27ChqtVr8/Pzk7bfflkWLFhXrqsBvvvlGwsLCpGHDhuLm5ibOzs7SqFEjef311yUxMVHRd926dfLII4+Ii4uL1K1bV95++2359ddfTb4n5q4KLO5rQ0JC5OGHHzYba+Er50REcnJy5IsvvjDuu3r16tKsWTN57bXX5MyZMyIiEhsbK08//bTUr19f1Gq11KxZU0JCQmTt2rWKfS1evFgcHR3l8uXLRb5fRV0VOHr0aLP9//Of/0jTpk2N3+dp06bJ4sWLTb43RV0VOHPmTJN9ApDJkycbnxd1VWDhOM0dR0Rk165d0qFDB8XPz/Tp0wWAYlmHwq5cuSKjRo2SZs2aibu7u1SvXl1atWolX331lcmyHWvWrJHu3buLp6enqNVqqV+/vgwePFix3ElWVpa8/PLLUrt2bVGpVCbvUXBwsMnVvWQ9KhGuIEZU0IULF9CgQQPMnDkTb731lq3DIbI7mZmZqFevHiZMmICJEyfaOhyb6tOnDy5cuPDAqz2t5dy5c2jSpAk2bdpU4gVcyTI4FEhERCXi4uKCqVOnYsqUKYiIiIC7u7utQ7KK8ePHo02bNggICMCNGzfw008/YcuWLSZ3L7ClTz75BD179mRSZUNMrIiIqMReffVV3Lx5E+fPnzfO+ans9Ho9PvzwQ6SkpEClUqFFixZYunQpnn/+eVuHBsCwjlujRo2M8xnJNjgUSERERGQhXCCUiIiIyEKYWBERERFZCBMrIiIiIgvh5HUry8vLw+XLl+Hh4VHs21EQERGRbYkIbt26Ba1We98FYZlYWdnly5eLvFcbERER2bfExMT73tCeiZWV5d/sNDExEZ6enjaOhoiIiIojPT0dAQEBipuWm8PEysryh/88PT2ZWBEREVUwD5rGw8nrRERERBbCxIqIiIjIQphYEREREVkIEysiIiIiC2FiRURERGQhTKyIiIiILISJFREREZGFMLEiIiIishAmVkREREQWwsSKiIiIyEKYWBERERFZCBMrIiIiIgthYkVERESVQlYWcPu2bWNgYkVEREQV3rhxgIsL4OFh2ziq2fbwRERERKV39y7g5qZsEwFUKtvEw4oVERERVUi//26aVN28abukCmBiRURERBXQa68BXbrcez50qKFSpdHYLiaAQ4FERERUgWRkANWrK9u2bAF69bJNPIUxsSIiIqIKISYG6NFD2ZaebvsJ6wVxKJCIiIjsXni4Mql68UXD0J8xqdLrge3bgeXLDV/1ehtEyYoVERER2bH0dNN5Uzt2AF27FmiIjjast3Dp0r02f39gzhwgLMwqceZjxYqIiIjs0qZNpklVRoaZpGrwYGVSBQBJSYb26Ohyj7MgJlZERERkdwYPBvr1u/f8n/80DP0pllfQ6w2VKhHTHeS3RUZadViQQ4FERERkN9LSAG9vZVtsLNCxo5nOu3aZVqoKEgESEw39unWzZJhFYsWKiIiI7MK6daZJ1d27RSRVAJCcXLwdF7efBTCxIiIiIpvr3x946ql7z8ePNxScXFzu86I6dYq38+L2swAOBRIREZHNXL8O1K6tbPvjD6Bdu2K8ODjYcPVfUpL5eVYqlWF7cLBFYi0Om1asdu7ciQEDBkCr1UKlUmHNmjXGbTk5OZg4cSJatmwJd3d3aLVavPDCC7h8+bJiH1lZWRgzZgxq1aoFd3d3PPXUU7hUaLw1LS0N4eHh0Gg00Gg0CA8Px82bNxV9EhISMGDAALi7u6NWrVoYO3YssrOzFX2OHTuGkJAQuLq6om7duvjoo48g5r6RRERE9ECrVpkmVVlZxUyqAMDR0bCkAmB6g8D857NnG/pZiU0Tq4yMDDzyyCOYN2+eybY7d+7g0KFD+OCDD3Do0CFER0fj9OnTeKpgnRBAZGQkVq9ejaioKOzevRu3b99GaGgo9AWuABg+fDji4uKwceNGbNy4EXFxcQgPDzdu1+v16N+/PzIyMrB7925ERUVh1apVmDBhgrFPeno6evfuDa1WiwMHDmDu3Ln44osvMGvWrHJ4Z4iIiCq37t0NV/7le+89Q9HJ2bmEOwoLA1auBOrWVbb7+xvarbyOFcROAJDVq1fft8/+/fsFgFy8eFFERG7evClOTk4SFRVl7JOUlCQODg6yceNGERE5efKkAJC9e/ca+8TGxgoA+fPPP0VEZMOGDeLg4CBJSUnGPsuXLxe1Wi06nU5ERObPny8ajUYyMzONfaZNmyZarVby8vKKfZ46nU4AGPdLRERUlaSkiBhSqHuPI0cssOPcXJGYGJFlywxfc3MtsNN7ivv5XaEmr+t0OqhUKtSoUQMAcPDgQeTk5KBPnz7GPlqtFkFBQdizZw8AIDY2FhqNBh06dDD26dixIzQajaJPUFAQtFqtsU/fvn2RlZWFgwcPGvuEhIRArVYr+ly+fBkXLlwoMuasrCykp6crHkRERFXRsmWAn9+9566uQHY20KqVBXbu6GhYUmHYMMNXKw7/FVRhEqvMzEy8++67GD58ODw9PQEAKSkpcHZ2hpeXl6Kvr68vUlJSjH18fHxM9ufj46Po4+vrq9ju5eUFZ2fn+/bJf57fx5xp06YZ53ZpNBoEBASU5LSJiIgqPBGgQwdgxIh7bR9/DNy5Azg52S6u8lAhEqucnBwMHToUeXl5mD9//gP7iwhUBSaxqQpPaLNQH/l74rq51+abNGkSdDqd8ZGYmPjA+ImIiCqLy5cBBwdg//57bSdPAu+/b7uYypPdJ1Y5OTl47rnnEB8fjy1bthirVQDg5+eH7OxspKWlKV5z9epVYzXJz88PV65cMdnvtWvXFH0KV53S0tKQk5Nz3z5Xr14FAJNKVkFqtRqenp6KBxERUVXw/ffKOeXe3kBuLtC8ue1iKm92nVjlJ1VnzpzBb7/9hpo1ayq2t2vXDk5OTtiyZYuxLTk5GcePH0fnzp0BAJ06dYJOp8P+Aqnyvn37oNPpFH2OHz+O5AIrs27evBlqtRrt/r7ms1OnTti5c6diCYbNmzdDq9UiMDDQ4udORERUUYkALVsCL710r23mTCA11WZTn6xGJWK7hZhu376Ns2fPAgDatGmDWbNmoXv37vD29oZWq8UzzzyDQ4cOYf369YqqkLe3N5z/vh7zjTfewPr16/Hf//4X3t7eeOutt5CamoqDBw/C8e/v3hNPPIHLly/jm2++AQC8+uqrqF+/PtatWwfAsNxC69at4evri5kzZ+LGjRsYNWoUBg0ahLlz5wIwTJxv2rQpevTogX/96184c+YMRo0ahQ8//FCxLMODpKenQ6PRQKfTsXpFRESVTkICUL++su30aaBJE9vEYynF/vy26LWIJRQTEyMATB4jR46U+Ph4s9sASExMjHEfd+/elYiICPH29hZXV1cJDQ2VhIQExXFSU1NlxIgR4uHhIR4eHjJixAhJS0tT9Ll48aL0799fXF1dxdvbWyIiIhRLK4iIHD16VIKDg0WtVoufn59MmTKlREstiHC5BSIiqrwWLFAuo+DvL6LX2zoqyyju57dNK1ZVEStWRERU2eTlGSpS58/fa/v6a2DMGNvFZGnF/fzmvQKJiIio1M6fBxo1Mm1r0MA28diaXU9eJyIiIvs1e7YyqXroIUP1qqomVQArVkRERFRCer3hVnwFVyH65hvg1VdtF5O9YGJFRERExXb6NNC0qbItIQHgjUUMOBRIRERExTJ9ujKpat3aMPTHpOoeVqyIiIjovnJzgZo1gfT0e20//AC88ILtYrJXTKyIiIioSNu3A927K9suXwbq1LFJOHaPQ4FERERkVo8eyqSqc2fD0B+TqqKxYkVEREQKmZmAq6uybd48YPRo28RTkTCxIiIiIqNNm4B+/ZRtVXnBz5JiYkVEREQAgMceAw4cULbxxnclwzlWREREVdydO4BKpUyqPv2USVVpsGJFRERUkF4P7NoFJCcbZmkHBwOOjraOqtz873/AoEHKtkuXgLp1bRJOhcfEioiIKF90NDBunCGzyOfvD8yZA4SF2S6uctKiBXDqlLKNVaqy4VAgERERYEiqBg9WJlUAkJRkaI+Otk1c5eDWLcPQX8Gk6quvmFRZAhMrIiIivd5QqTKXWeS3RUYa+lVwK1YAnp7KtpQUw+lR2XEokIiIaNcu00pVQSJAYqKhX7duVgvL0vz9DQW4fA4OlSJXtCusWBERESUnW7afnbl50zD0VzCpWriwGEmVXm+4p83y5YavzMIeiBUrIiKi4t6jpQLey+WHH4BRo5Rt168bbqp8X1VsIr+lqEQ4Vc2a0tPTodFooNPp4Fl4kJuIiGxDrwcCAw0lHXMfiyqVIamIj69QSy9oNEB6+r3nNWoAaWnFeGH+RP7C74VKZfi6cmWVS66K+/nNoUAiIiJHR0MlBriXPOTLfz57doVJqq5fN4RdMKn64YdiJlVVaCJ/eWBiRUREBBgqMCtXmq6M6e9foSo0CxcCtWsr29LSgBdeKOYOSjKRn0xwjhUREVG+sDBg4MAKu/J64WJbQACQkFDCnVTyifzljYkVERFRQY6OFW5JhZQU03n1K1YAzz1Xip1V4on81sChQCIiogrsq69Mc5xbt0qZVAGGCp2/v2n5K59KZSiFBQeX8gCVGxMrIiKiCkqlAsaPv/e8RQvDFKjq1cuw00o2kd/amFgRERFVMJcumeY8//sfcOKEhQ5QSSby2wLnWBEREVUgn34KvP++si0jA3Bzs/CBKvhEflthYkVERFRBFK5SdegA7N1bjgesgBP5bY1DgURERHZu3z7TpGrTpnJOqqhUWLEiIiKyY40aAefPK9syMwG12jbx0P0xsSIiIrJDIoCDmXEl3uHXvnEokIiIyM5s326aVM2fz6SqImDFioiIyI54e5veLPnuXcDFxTbxUMkwsSIiIrIDeXnmVzJglapi4VAgERGRjf36q2lS9cMPTKoqIlasiIiIbMjcLfmyswEnJ+vHQmXHxIqIiMgG9HqgmplPYVapKjYOBRIREVnZqlWmSdXKlUyqKgNWrIiIiKzI3NBfbi5vwVdZsGJFRERkBTk55pMqESZVlQkTKyIionK2ZAng7Kxs27CBQ3+VEYcCiYiIypG5KpVeb/52NVTx8dtKRERUDjIzTZMqL6+i7wFIlQO/tURERBa2cCHg6qps274duHGjDDvV6w07Wb7c8FWvL8POqLxwKJCIiMiCzA395eWZby+26Ghg3Djg0qV7bf7+wJw5QFhYGXZMlsaKFRERkQXcvm2aPDVqZBj6K3NSNXiwMqkCgKQkQ3t0dBl2TpbGxIqIiKiMZs4EPDyUbXv3AmfPlnHHer2hUmXu8sH8tshIDgvaEQ4FEhERlUFRa1NZxK5dppWqwgdKTDT069bNQgelsmDFioiIqBR0OtOkqk0bC69NlZxs2X5U7phYERERldDkyUCNGsq2uDjg0CELH6hOHcv2o3LHoUAiIqISKNehv8KCgw1X/yUlmT+ISmXYHhxcTgFQSbFiRUREVAzXr5smVT17lvNtaRwdDUsqAKYHz38+ezZvNmhHmFgRERE9wPjxQO3ayrY//wR++80KBw8LA1auBOrWVbb7+xvauY6VXeFQIBER0X1YdeivKGFhwMCBhqv/kpMNc6qCg1mpskNMrIiIiMy4fNm0SPTMM4YikU04OnJJhQqAQ4FERESFvPyyaVJ1/rwNkyqqMFixIiIiKsAuhv6owmLFioiICMDx46ZJ1ahRTKqoZFixIiKiKs/bG0hLU7adPg00aWKbeKjiYmJFRESVj15f7CvoOPRHlsShQCIiqlyio4HAQKB7d2D4cMPXwEBDewEHDpgmVY8+yqSKyoYVKyIiqjyio4HBg02zo6QkQ/vfC2qaq1IlJAABAdYJkyovVqyIiKhy0OuBcePMl5zy2yIjixz6Y1JFlsDEioiIKoddu4BLl4rcvEOCoUpMULT17cuhP7IsDgUSEVHlkJxc5CYVTLOnK1cAH5/yDIiqIptWrHbu3IkBAwZAq9VCpVJhzZo1iu0igilTpkCr1cLV1RXdunXDiRMnFH2ysrIwZswY1KpVC+7u7njqqadwqdD/WNLS0hAeHg6NRgONRoPw8HDcvHlT0SchIQEDBgyAu7s7atWqhbFjxyI7O1vR59ixYwgJCYGrqyvq1q2Ljz76CML/6hAR2Yc6dcw2m0uqRJhUUfmwaWKVkZGBRx55BPPmzTO7fcaMGZg1axbmzZuHAwcOwM/PD71798atW7eMfSIjI7F69WpERUVh9+7duH37NkJDQ6HX6419hg8fjri4OGzcuBEbN25EXFwcwsPDjdv1ej369++PjIwM7N69G1FRUVi1ahUmTJhg7JOeno7evXtDq9XiwIEDmDt3Lr744gvMmjWrHN4ZIiIqseBgwN/feKnfOoSaJFXD3NZAcvXmXk1kGWInAMjq1auNz/Py8sTPz08+//xzY1tmZqZoNBpZuHChiIjcvHlTnJycJCoqytgnKSlJHBwcZOPGjSIicvLkSQEge/fuNfaJjY0VAPLnn3+KiMiGDRvEwcFBkpKSjH2WL18uarVadDqdiIjMnz9fNBqNZGZmGvtMmzZNtFqt5OXlFfs8dTqdADDul4iILGjVKhGVSgw1KeUjDTUM24lKobif33Y7eT0+Ph4pKSno06ePsU2tViMkJAR79uwBABw8eBA5OTmKPlqtFkFBQcY+sbGx0Gg06NChg7FPx44dodFoFH2CgoKg1WqNffr27YusrCwcPHjQ2CckJARqtVrR5/Lly7hw4UKR55GVlYX09HTFg4iIyoc8HQaV5Jm2B9RDjVWLgbAwG0RFVYndJlYpKSkAAF9fX0W7r6+vcVtKSgqcnZ3h5eV13z4+ZgbSfXx8FH0KH8fLywvOzs737ZP/PL+POdOmTTPO7dJoNAjg9bxEROXi668Bh0KfaiHNr0BitgPx8UyqyCrs/qpAVaEFR0TEpK2wwn3M9bdEH/l74vr94pk0aRLGjx9vfJ6ens7kiojIwsz9Gb55E9BofAH4mm4kKid2W7Hy8/MDYFoNunr1qrFS5Ofnh+zsbKQVunNm4T5Xrlwx2f+1a9cUfQofJy0tDTk5Offtc/XqVQCmVbWC1Go1PD09FQ8iokpDrwe2bweWLzd81Vt3YnheXtH3+tNorBoKEQA7TqwaNGgAPz8/bNmyxdiWnZ2NHTt2oHPnzgCAdu3awcnJSdEnOTkZx48fN/bp1KkTdDod9u/fb+yzb98+6HQ6RZ/jx48jucAaKJs3b4ZarUa7du2MfXbu3KlYgmHz5s3QarUIDAy0/BtARGTvinlPvvIydarpfZXN3c2GyKrKfx590W7duiWHDx+Ww4cPCwCZNWuWHD58WC5evCgiIp9//rloNBqJjo6WY8eOybBhw6ROnTqSnp5u3Mfrr78u/v7+8ttvv8mhQ4ekR48e8sgjj0hubq6xT79+/aRVq1YSGxsrsbGx0rJlSwkNDTVuz83NlaCgIOnZs6ccOnRIfvvtN/H395eIiAhjn5s3b4qvr68MGzZMjh07JtHR0eLp6SlffPFFic6ZVwUSUaXw99V3JpfeqVSGRzlffWfuqr+MjHI9JFVxxf38tmliFRMTIwBMHiNHjhQRw5ILkydPFj8/P1Gr1dK1a1c5duyYYh93796ViIgI8fb2FldXVwkNDZWEhARFn9TUVBkxYoR4eHiIh4eHjBgxQtLS0hR9Ll68KP379xdXV1fx9vaWiIgIxdIKIiJHjx6V4OBgUavV4ufnJ1OmTCnRUgsiTKyIqBLIzRXx9zef3eQnVwEBhn4WlpNj/pBE5a24n98qERZNrSk9PR0ajQY6nY7zrYioYtq+3TDs9yAxMUC3bhY77Lhxhiv/CnrtNWDhQosdgqhIxf38tvurAomIyM7c5558pepXDOYmqGdlAc7OFjsEkUXY7eR1IiKyU0Xck6/U/e4jM7Poq/6YVJE9YmJFREQlU+iefCZUKiAgwNCvDMLDAVdXZdukSbzqj+wbhwKJiKhkHB2BOXMMaxuoVMpMJz/Zmj3bdC2EEjCXs+XmlmmXRFbBihUREZVcWBiwciVQt66y3d/f0F7K28fculX00B+TKqoImFgREVHphIUBFy4Yrv5btszwtQz35HviCaDwxVYzZnDojyoWDgUSEVHpOTpaZEkFc1Wqom5XQ2TPWLEiIiKbSU0teuiPSRVVREysiIjIJtq2BWrVUrYtWsShP6rYOBRIRERWV1SViqiiY8WKiIis5vJlJlVUuTGxIiKyFr3ecJ+95csNX/V6W0dkVQEBpqszrFjBpIoqFw4FEhFZQ3S04S7Cly7da/P3Nyy0WcrlCSoSVqmoqmDFioiovEVHG1YpL5hUAUBSkqE9Oto2cVnB+fNMqqhqYWJFRFSe9HpDpcpcJpHfFhlZKYcFnZ2BRo2UbRs2MKmiyo1DgURE5WnXLtNKVUEiQGKioZ8FFtq0F6xSUVXFihURUXlKTrZsPzt3/DiTKqramFgREZWnOnUs28+OqVRAy5bKtl27mFRR1cKhQCKi8hQcbLj6LynJfIahUhm2BwdbPzYLYpWKyIAVKyKi8uToaFhSATDNPvKfz55t6FcBbdvGpIqoICZWRETlLSwMWLnSdHVMf39Du63XsSrlwqUqFdCzp7Lt0CEmVVS1cSiQiMgawsKAgQMNk46Skw1zqoKDbV+pKuXCpaxSEZmnEuGvgjWlp6dDo9FAp9PB09PT1uEQUVWWv3Bp4Y+B/KzJTDVt9Wrz+RY/SaiyK+7nN4cCiYiqolIsXKpSmSZVhw8zqSIqiIkVEVFVVJKFS1H00F/r1uUTHlFFxcSKiKgqKuaCpP+NcuF8KqIS4OR1IqKqqBgLkqogwDfKttOngSZNyikmokqAiRURUVX0gIVLVTBtY5WK6ME4FEhEVBUVsXDpLLzJpIqoDJhYERFVVYUWLlVBMAGzFF0uXWJSRVQSTKyIiKqysDBI/IUiq1SFF4snovtjYkVEVIW9/z7g4KRc/b1GDVapiEqLk9eJiKooc8soXLsG1Kpl/ViIKgsmVkREVUxenvlbFLJKRVR2HAokIqpCXnvNNKlq3pxJFZGlsGJFRFRFmBv6S08HPDysHwtRZcXEioioksvJAZydTdtZpSKyPA4FEhFVYs88Y5pUde/OpIqovLBiRURUSZkb+rt7F3BxsX4sRFUFK1ZERJXM3bvmkyoRJlVE5Y2JFRFRJfL444Cbm7Jt6FAO/RFZC4cCiYgqCXNVqpwcoBr/0hNZTakqVnfv3sWdO3eMzy9evIjZs2dj8+bNFguMiIiKR6creuiPSRWRdZUqsRo4cCCWLFkCALh58yY6dOiAL7/8EgMHDsSCBQssGiARERWtYUPDvf0KGjOGQ39EtlKqxOrQoUMIDg4GAKxcuRK+vr64ePEilixZgq+//tqiARIRkXkqFRAfr2zLywP4Z5jIdkqVWN25cwcefy/Vu3nzZoSFhcHBwQEdO3bExYsXLRogEREpXbtW9NCfuXYisp5SJVaNGzfGmjVrkJiYiE2bNqFPnz4AgKtXr8LT09OiARIR0T1uboCPj7JtyhQO/RHZi1JNa/zwww8xfPhwvPnmm+jRowc6deoEwFC9atOmjUUDJCIiA3PVqLw8VqmI7IlKpHT/z0lJSUFycjIeeeQRODgYCl/79++Hp6cnmjVrZtEgK5P09HRoNBrodDpW94ioWBISgPr1TdtZpSKynuJ+fpd6gVA/Pz94eHhgy5YtuHv3LgDg0UcfZVJFRGRBKpVpUjV3LpMqIntVqqHA1NRUPPfcc4iJiYFKpcKZM2fQsGFDvPzyy6hRowa+/PJLS8dJRFTlFDVBnYjsV6kqVm+++SacnJyQkJAAtwL3ThgyZAg2btxoseCIiKqiP/9kUkVUUZWqYrV582Zs2rQJ/v7+ivYmTZpwuQUiojIwl1D9+CMwYoT1YyGikitVYpWRkaGoVOW7fv061Gp1mYMiIrI4vR7YtQtITgbq1AGCgwFHR1tHpcAqFVHFV6qhwK5duxpvaQMAKpUKeXl5mDlzJrp3726x4IiILCI6GggMBLp3B4YPN3wNDDS024GDB5lUEVUWpapYzZw5E926dcMff/yB7OxsvPPOOzhx4gRu3LiB33//3dIxEhGVXnQ0MHiwaZaSlGRoX7kSCAuzTWwwn1CtWweEhlo/FiIquzKtY7VgwQIcPHgQeXl5aNu2LUaPHo06depYOsZKhetYEVmRXm+oTF26ZH67SgX4+xtuuGeDYUFWqYgqjuJ+fpc6saLSYWJFZEXbtxuG/R4kJgbo1q28ozEqKiz+NSayX8X9/C72UODRo0cRFBQEBwcHHD169L59W7VqVfxIiYjKS3KyZftZgLkq1Y4dQNeuVguBiMpRsROr1q1bIyUlBT4+PmjdujVUKhXMFbtUKhX0er1FgyQiKpXiTk2w0hQGDv0RVX7FTqzi4+NRu3Zt47+JiOxecLBhDlVSkvkMJn+OVXCw5Y9dYHmHH4+3RvhnzU26MKkiqnyKnVjV//tmVTk5OZgyZQo++OADNGzYsNwCIyIqM0dHYM4cw9V/KpUyk8kvH82ebfmJ69HRwLhxwKVLUME0e/r9d6BzZ8sekojsQ4nXsXJycsLq1avLIxYiIssLCzMsqVC3rrLd3798llrIX96hiKRKVkUzqSKqxEq1QOjTTz+NNWvWWDgUIqJyEhYGXLhguPpv2TLD1/h4yydVej0wbhy+lgjzSZXKAYiMNPQjokqpVAuENm7cGB9//DH27NmDdu3awd3dXbF97NixFgmOiMhiHB3Lf0mFXbugupRo0nwULdESxwEBkJhomHtlxeUdiMh6SrWOVYMGDYreoUqF8+fPlymoyozrWBFVXmav+oOZxmXLgGHDyj8gIrKY4n5+l2ooMD4+vsiHJZOq3NxcvP/++2jQoAFcXV3RsGFDfPTRR8jLyzP2ERFMmTIFWq0Wrq6u6NatG06cOKHYT1ZWFsaMGYNatWrB3d0dTz31FC4VWok5LS0N4eHh0Gg00Gg0CA8Px82bNxV9EhISMGDAALi7u6NWrVoYO3YssrOzLXa+RFQxffhhCZIqwGrLOxCR9ZUqsbKW6dOnY+HChZg3bx5OnTqFGTNmYObMmZg7d66xz4wZMzBr1izMmzcPBw4cgJ+fH3r37o1bt24Z+0RGRmL16tWIiorC7t27cfv2bYSGhirW2xo+fDji4uKwceNGbNy4EXFxcQgPDzdu1+v16N+/PzIyMrB7925ERUVh1apVmDBhgnXeDCKySyoV8PHHyrZzaGQ+qVKpgICA8lnegYjsQqlvaXPp0iWsXbsWCQkJJlWbWbNmWSS40NBQ+Pr6YvHixca2Z555Bm5ubli6dClEBFqtFpGRkZg4cSIAQ3XK19cX06dPx2uvvQadTofatWtj6dKlGDJkCADg8uXLCAgIwIYNG9C3b1+cOnUKLVq0wN69e9GhQwcAwN69e9GpUyf8+eefaNq0KX799VeEhoYiMTERWq0WABAVFYVRo0bh6tWrxR7W41AgUeUgAjiY+a+prPr7qsD8TvnyS1o2vukzEZVOuQ4Fbt26FU2bNsX8+fPx5ZdfIiYmBt9//z3+85//IC4urrQxm+jSpQu2bt2K06dPAwCOHDmC3bt348knnwRgGJJMSUlBnz59jK9Rq9UICQnBnj17AAAHDx5ETk6Ooo9Wq0VQUJCxT2xsLDQajTGpAoCOHTtCo9Eo+gQFBRmTKgDo27cvsrKycPDgwSLPISsrC+np6YoHEVVsr79eRFIlsP7yDkRkV0p1VeCkSZMwYcIEfPTRR/Dw8MCqVavg4+ODESNGoF+/fhYLbuLEidDpdGjWrBkcHR2h1+vx6aefYtjfkz5TUlIAAL6+vorX+fr64uLFi8Y+zs7O8PLyMumT//r8W/UU5uPjo+hT+DheXl5wdnY29jFn2rRpmDp1aklOm4jsmLm5VMnJgJ9fgYawMGDgQOPK66hTxzD8Z+mFSInI7pQqsTp16hSWL19u2EG1arh79y6qV6+Ojz76CAMHDsQbb7xhkeBWrFiBH3/8EcuWLcPDDz+MuLg4REZGQqvVYuTIkcZ+qkJ/6UTEpK2wwn3M9S9Nn8ImTZqE8ePHG5+np6cjICDgvrERkf3JyzOfFxU5mcIayzsQkd0p1VCgu7s7srKyABiG1c6dO2fcdv36dctEBuDtt9/Gu+++i6FDh6Jly5YIDw/Hm2++iWnTpgEA/P7+L2LhitHVq1eN1SU/Pz9kZ2cjLS3tvn2uXLlicvxr164p+hQ+TlpaGnJyckwqWQWp1Wp4enoqHkRUsTz9dAmTKiKqskqVWHXs2BG///47AKB///6YMGECPv30U7z00kvo2LGjxYK7c+cOHApNZHB0dDQut9CgQQP4+flhy5Ytxu3Z2dnYsWMHOv99z4h27drByclJ0Sc5ORnHjx839unUqRN0Oh32799v7LNv3z7odDpFn+PHjyM5OdnYZ/PmzVCr1WjXrp3FzpmI7ItKBRS+0URaGpMqIiqClMK5c+fkyJEjIiKSkZEhb7zxhrRs2VKefvppuXDhQml2adbIkSOlbt26sn79eomPj5fo6GipVauWvPPOO8Y+n3/+uWg0GomOjpZjx47JsGHDpE6dOpKenm7s8/rrr4u/v7/89ttvcujQIenRo4c88sgjkpuba+zTr18/adWqlcTGxkpsbKy0bNlSQkNDjdtzc3MlKChIevbsKYcOHZLffvtN/P39JSIiokTnpNPpBIDodLoyvDNEVN6ys0UM6ZPyQURVU3E/v+36z0R6erqMGzdO6tWrJy4uLtKwYUN57733JCsry9gnLy9PJk+eLH5+fqJWq6Vr165y7NgxxX7u3r0rERER4u3tLa6urhIaGioJCQmKPqmpqTJixAjx8PAQDw8PGTFihKSlpSn6XLx4Ufr37y+urq7i7e0tERERkpmZWaJzYmJFZP86dDBNqOrWtXVURGRLxf38LvU6VlQ6XMeKyL6ZuxYlIwNwc7N+LERkP4r7+V3sqwK9vLweeKVdvhs3bhR3t0REduHuXfPJE//rSUQlUezEavbs2eUYBhGR7QQEAIVuH4rHHgP27bNNPERUcRU7sSq4bhQRUWVhrhCfnQ04OVk/FiKq+Eq1QGhBd+/eRU5OjqKNc4eIyN7dvAkUuiEDAA79EVHZlGodq4yMDERERMDHxwfVq1eHl5eX4kFEZM9UKtOkauBAJlVEVHalSqzeeecdbNu2DfPnz4darcZ3332HqVOnQqvVYsmSJZaOkYjIYswN/en1pouAEhGVRqmGAtetW4clS5agW7dueOmllxAcHIzGjRujfv36+OmnnzBixAhLx0lEVCYpKYZ7IRfGKhURWVKpKlY3btxAgwYNABjmU+Uvr9ClSxfs3LnTctEREVmASmWaVL36KpMqIrK8UiVWDRs2xIULFwAALVq0wM8//wzAUMmqUaOGpWIjIiozc0N/eXnAN99YPxYiqvxKlVi9+OKLOHLkCABg0qRJxrlWb775Jt5++22LBkhEVBrx8eaTKhHz7URElmCRW9okJCTgjz/+QKNGjfDII49YIq5Ki7e0ISp/5hKnDz4APvrI+rEQUeVg8VvaAMC+fftw48YNPPHEE8a2JUuWYPLkycjIyMCgQYMwd+5cqNXq0kdORFQGRVWpiIisoURDgVOmTMHRo0eNz48dO4Z//OMf6NWrFyZNmoR169Zh2rRpFg+SiOhBjh1jUkVEtleixCouLg49e/Y0Po+KikKHDh3w7bff4s0338TXX39tnMhORGQtKhXQqpWybfZsJlVEZH0lGgpMS0uDr6+v8fmOHTvQr18/4/NHH30UiYmJlouOiOgBWKUiIntSooqVr68v4uPjAQDZ2dk4dOgQOnXqZNx+69YtOPHOpURkBVu3MqkiIvtTosSqX79+ePfdd7Fr1y5MmjQJbm5uCA4ONm4/evQoGjVqZPEgiYgKUqmAXr2UbfPmMakiItsr0VDgJ598grCwMISEhKB69er44Ycf4OzsbNz+n//8B3369LF4kERE+VilIiJ7Vqp1rHQ6HapXrw5HR0dF+40bN1C9enVFskVKXMeKqHRWrgSefda0nUkVEVlDuaxjlU+j0Zht9/b2Ls3uiIjuy1yVKioKGDLE+rEQEd1PqRIrIiJr4dAfEVUkpbpXIBFReVu0iEkVEVU8rFgRkd0xl1Bt2gTw2hgisndMrIjIrrBKRUQVGYcCicgufPopkyoiqvhYsSIimzOXUO3dC3ToYP1YiIjKgokVEdkUq1REVJlwKJCIbGLMGCZVRFT5sGJFRFZnLqE6eRJo3tz6sRARWRITKyKyGhHAwUydnFUqIqosOBRIRFbx3HNMqoio8mPFiojKnbmhv4QEICDA+rEQEZUnJlZEVG7y8gBHR9N2VqmIqLLiUCARlYsuXZhUEVHVw4oVEVmcuaG/a9eAWrVKsBO9Hti1C0hOBurUAYKDzWdqRER2hIkVEVlMTg7g7GzaXuIqVXQ0MG4ccOnSvTZ/f2DOHCAsrEwxEhGVJw4FEpFF1KtnwaRq8GBlUgUASUmG9ujoUsdIRFTemFgRUZmpVEBiorLt1q1SJFV6vaFSZe6F+W2RkYZ+RER2iIkVEZXanTtF35amevVS7HDXLtNKVeEdJyYa+hER2SEmVkRUKioV4O6ubPP2LuNVf8nJlu1HRGRlnLxORCVmrkqVlWV+jlWJ1Klj2X5ERFbGihURFVtaWtFDf2VOqgDDkgr+/uYPAhjaAwIM/YiI7BATKyIqFpXKMNRXUOvWFl7w09HRsKRC/gELBwAAs2cr17PS64Ht24Hlyw1fObGdiGyIiRURPZC5AlJuLnD4cDkcLCwMWLkSqFtX2e7vb2gvuI5VdDQQGAh07w4MH274GhjIJRmIyGZUIrzBhDWlp6dDo9FAp9PB09PT1uEQ3VdyMqDVmrZb5a/Gg1Zez1/vqnAw+Vlg4SSMiKgMivv5zcTKyphYUUVhrkoVGgqsW2f9WEzo9YbKVFFLM6hUhgpXfDxvg0NEFlHcz29eFUhEJswlVXl5Rc8pt7qSrHfVrZvVwiIi4hwrIjI6e7boq/7sJqkCuN4VEdktJlZE5aECXqmmUgFNmijbXn7ZSvOpSorrXRGRneJQIJGlRUcb7ndXcKjK39+wjICdTqYuqkplt/LXu0pKMh9o/hwrrndFRFbGihWRJeVfqVZ4/k9SkqHdzpYBOHy4AiZVQOnWuyIisgImVkSWotcbKlXmspL8tshIuxkWVKmAtm2Vbe+9VwGSqnwlWe+KiMhKOBRIZCkV6Eq1ClmlMicsDBg48P7rXRERWRETKyJLqQBXqu3bB3TsaNpeIZOqfI6ONk9UiYjycSiQyFLs/Eo1lco0qfr66wqeVBER2RlWrIgsxY6vVKs0Q39ERHaOFSsiS7HDK9ViYphUERFZExMrIkuyoyvVVCqgRw9l24YNTKqIiMoThwKJLM0OrlRjlYqIyDaYWBGVBxtdqfa//wGDBpm2M6kiIrIOJlZElYS5KtXu3cDjj1sxCL2ea0oRUZXGxIqoErCLob8KeI9EIiJL4+R1ogrsv/+1o6SqAt0jkYiovDCxIqqgVCrgxReVbUeO2CCpqmD3SCQiKk8cCiQqCTuZQ2QXVap8FegeiURE5c3uK1ZJSUl4/vnnUbNmTbi5uaF169Y4ePCgcbuIYMqUKdBqtXB1dUW3bt1w4sQJxT6ysrIwZswY1KpVC+7u7njqqadwqdAHQVpaGsLDw6HRaKDRaBAeHo6bN28q+iQkJGDAgAFwd3dHrVq1MHbsWGRnZ5fbuZOdiY4GAgOB7t2B4cMNXwMDrTrMNWuWnSVVQIW4RyIRkbXYdWKVlpaGxx9/HE5OTvj1119x8uRJfPnll6hRo4axz4wZMzBr1izMmzcPBw4cgJ+fH3r37o1bt24Z+0RGRmL16tWIiorC7t27cfv2bYSGhkJfYGhi+PDhiIuLw8aNG7Fx40bExcUhPDzcuF2v16N///7IyMjA7t27ERUVhVWrVmHChAlWeS/IxuxgDpFKBRT+cTt71g6WUrDzeyQSEVmV2LGJEydKly5dityel5cnfn5+8vnnnxvbMjMzRaPRyMKFC0VE5ObNm+Lk5CRRUVHGPklJSeLg4CAbN24UEZGTJ08KANm7d6+xT2xsrACQP//8U0RENmzYIA4ODpKUlGTss3z5clGr1aLT6Yp9TjqdTgCU6DVkY7m5Iv7+IoYcxvShUokEBBj6lRNzh7Ub+e+PSmWz94eIqLwV9/PbritWa9euRfv27fHss8/Cx8cHbdq0wbfffmvcHh8fj5SUFPTp08fYplarERISgj179gAADh48iJycHEUfrVaLoKAgY5/Y2FhoNBp06NDB2Kdjx47QaDSKPkFBQdBqtcY+ffv2RVZWlmJokiqhkswhsrD33rPDob/C7PAeiUREtmLXidX58+exYMECNGnSBJs2bcLrr7+OsWPHYsmSJQCAlJQUAICvr6/idb6+vsZtKSkpcHZ2hpeX1337+Pj4mBzfx8dH0afwcby8vODs7GzsY05WVhbS09MVD6pgbDSHSKUCPvtM2Xb5sp0lVfns6B6JRES2ZNdXBebl5aF9+/b47O9PlzZt2uDEiRNYsGABXnjhBWM/VaH/JYuISVthhfuY61+aPoVNmzYNU6dOvW8sZOesPIdIBHAw818eu0yoCrKDeyQSEdmaXVes6tSpgxYtWijamjdvjoSEBACAn58fAJhUjK5evWqsLvn5+SE7OxtpaWn37XPlyhWT41+7dk3Rp/Bx0tLSkJOTY1LJKmjSpEnQ6XTGR2Ji4gPPm+xMcLCh8lJUAq1SAQEBhn5l9OqrpkmVq2sFSKry5d8jcdgww1cmVURUxdh1YvX444/jr7/+UrSdPn0a9evXBwA0aNAAfn5+2LJli3F7dnY2duzYgc6dOwMA2rVrBycnJ0Wf5ORkHD9+3NinU6dO0Ol02L9/v7HPvn37oNPpFH2OHz+O5ALDPZs3b4ZarUa7du2KPAe1Wg1PT0/FgyoYK80hUqmAAlMIAQA3bgB37pRpt0REZE1WmEhfavv375dq1arJp59+KmfOnJGffvpJ3Nzc5McffzT2+fzzz0Wj0Uh0dLQcO3ZMhg0bJnXq1JH09HRjn9dff138/f3lt99+k0OHDkmPHj3kkUcekdwCVyn169dPWrVqJbGxsRIbGystW7aU0NBQ4/bc3FwJCgqSnj17yqFDh+S3334Tf39/iYiIKNE58arACmzVKtOrAwMCDO1lkJtr51f9ERFRsT+/7f7P97p16yQoKEjUarU0a9ZMFi1apNiel5cnkydPFj8/P1Gr1dK1a1c5duyYos/du3clIiJCvL29xdXVVUJDQyUhIUHRJzU1VUaMGCEeHh7i4eEhI0aMkLS0NEWfixcvSv/+/cXV1VW8vb0lIiJCMjMzS3Q+TKwquNxckZgYkWXLDF/LuITAU0+ZJlRNmlgkUiIisqDifn6rRCrM7I1KIT09HRqNBjqdjsOCVZy5KVu3bwPu7taPhYiI7q+4n992fVUgUWWUlQW4uJi2l+i/OKW9Z6Gd3OuQiKiysuvJ60SVTceOpklVcHAJk6rS3rPQDu51SERU2XEo0Mo4FFiBWLi6Y27oLysLcHYuwU7y71lY+Nc2f+dFLcZZ2tcRERGA4n9+M7GyMiZWFUR0NDBunPJWNv7+hmUXSpiA3L4NeHiYtpf4N0+vN1SYirq9jkpliDE+XpkAlvZ1RERkVNzPbw4FEhWWX90pnIgkJRnaSzB0Vq+eaVL17LOlXPCztPcstOG9DomIqhpOXicqSK83VKrMZT4ihupOZKTh1i0PqO6YG/rLzS1DUai09yy00b0OiYiqIlasiAqyQHXn1i3zSZVIGUfaSnvPQivf65CIqCpjYkVUUBmrO889BxQeeo+IsNC9/kp7z8LgYKBmzfvvu2ZNi9zrkIioquNQIFFBZajumMt38vKKzoNKLP+ehYMHG3ZaMFuz4D0LiYio9FixIiqoFFWh1NSih/4sllTlCwszLI1Qt66y3d+/6CUTdu0yBHk/qamcvE5EZAFMrIgKyq8KAaZZkZmqUK9eQK1aym4rVgCSqwe2bweWLzd81estF2NYGHDhAhATAyxbZvgaH1/0MhCcvE5EZDUcCiQqLL8qZG4dq9mzjQlMUVUqwwrnllkDq0iOjkC3bsXry8nrRERWwwVCrYwLhFYgRay8npwMaLWm3Y1Jlb2tcJ6/QGhSkvlZ9FwglIjogbhAKFFZ5VeFhg0zfHV0xCOPmCZVv/76d77yoDWwAMMaWJYcFiyOEg5vEhFR6TGxIiomlQo4elTZJgL06/f3E3te4bw0k96JiKjEOMeK6AHi44GGDU3bTQpT9j5JPCzMsGK8BW8sTURESkysiO6jTRsgLk7ZtmsX0KWLmc4VYZJ4SSa9ExFRiTGxIipCkVf9FSV/DawHTRLnCudERJUW51gRFXLhQimSKoCTxImIiIkVUUG9egENGijb/vqrBPf64yRxIqIqjUOBRH8rVZXKHE4SJyKqsphYUZX3119As2bKtt69gc2by7BTThInIqqSmFhRlWbuqr+LF4F69WwSDhERVXBMrKjKstjQHxER0d84eZ2qnCNHTJOqZ59lUkVERGXHihVVKfXqGe4qU1ByMuDnZ5t4iIiocmFiRVUGh/6IiKi8cSiQKr29e02TqldeYVJFRESWx4oVVWoeHsDt28q21FTA29s28RARUeXGxIoqLQ79ERGRtXEokCqdmBjTpGrCBCZVRERU/lixokrFXJVKpwM8Pa0fCxERVT1MrKhSEAEczNRfWaUiIiJr4lAgVXjr15smVR99xKSKiIisjxUrqtDMDf3duQO4ulo/FiIiIiZWVCHl5QGOjqbtrFIREZEtcSiQKpwVK0yTqq++YlJFRES2x4oVVSjmhv6ysgBnZ+vHQkREVBgTK6oQcnMBJyfTdlapiIjInnAokOze4sWmSdV33zGpIiIi+8OKFdk1c0N/ubnmJ64TERHZGitWZJdyc4u+1x+TKiIisldMrKoSvR7Yvh1YvtzwVa+3dURm/d//mQ79rVjBoT8iIrJ/HAqsKqKjgXHjgEuX7rX5+wNz5gBhYbaLq5DatYHr15Vter3529UQERHZG35cVQXR0cDgwcqkCgCSkgzt0dG2iauA7GzD0F/BpKp796LvAUhERGSP+JFV2en1hkqVuXG0/LbISJsOC65cCajVyrY//gC2bbNNPERERKXFocDKbtcu00pVQSJAYqKhX7duVgsrn7MzkJOjbMvLMz9xnYiIyN6xYlXZJSdbtp+F3LljSJ4KJlUDBxryPCZVRERUUTGxquzq1LFsPwtYsgRwd1e2HTsGrFljtRCIiIjKBYcCK7vgYMPVf0lJ5udZqVSG7cHBVgmnqLWpiIiIKgNWrCo7R0fDkgqAaVaT/3z27HJfdfP2bdPDP/88kyoiIqpcmFhVBWFhhkvv6tZVtvv7G9rLeR2rb74BPDyUbadPA0uXluthiYiIrI5DgVVFWJhhdviuXYaJ6nXqGIb/yrlSZXboL2Y78EcykGSdGIiIiKyFiVVV4uhotSUVbt4EvLyUbW/0PY/5J0KA7va9+jsREVFpcSiQLG7WLNOk6sKCXzF/c2O7Xv2diIiorFixIosyO/SXqwcCXy169XeVyrD6+8CBHBYkIqIKjRUrsohr10yTqnfe+TuXKsnq70RERBUYEysqs48/Bnx8lG1JScD06X8/sdPV34mIiCyNQ4FUJsVa8NMOV38nIiIqD6xYUakkJ5smVVOmFLHgZ/7q70XdBFClAgICrLb6OxERUXlhYkUlNnEioNUq265eBSZPLuIFdrL6OxERUXljYkUlolIBM2Yo20SA2rUf8EIbr/5ORERkDUysqFguXjQtNn3xRQnv9RcWBly4AMTEAMuWGb7GxzOpIiKiSoOT1+mBRo8G5s9Xtt24YboIaLFYcfV3IiIia2NiRfdVrKv+iIiICACHAqkIZ86YJlXz5zOpIiIiup8KlVhNmzYNKpUKkZGRxjYRwZQpU6DVauHq6opu3brhxIkTitdlZWVhzJgxqFWrFtzd3fHUU0/hUqGVwNPS0hAeHg6NRgONRoPw8HDcvHlT0SchIQEDBgyAu7s7atWqhbFjxyI7O7u8TtdmRo4EHnpI2ZaeDrzxhhWD0OuB7duB5csNX/V6Kx6ciIiodCpMYnXgwAEsWrQIrVq1UrTPmDEDs2bNwrx583DgwAH4+fmhd+/euHXrlrFPZGQkVq9ejaioKOzevRu3b99GaGgo9AU+rIcPH464uDhs3LgRGzduRFxcHMLDw43b9Xo9+vfvj4yMDOzevRtRUVFYtWoVJkyYUP4nb0UqFbBkibJNBPDwsGIQ0dFAYCDQvTswfLjha2Agb9RMRET2TyqAW7duSZMmTWTLli0SEhIi48aNExGRvLw88fPzk88//9zYNzMzUzQajSxcuFBERG7evClOTk4SFRVl7JOUlCQODg6yceNGERE5efKkAJC9e/ca+8TGxgoA+fPPP0VEZMOGDeLg4CBJSUnGPsuXLxe1Wi06na7Y56LT6QRAiV7zQLm5IjExIsuWGb7m5pZ4F8ePixhSqHuP//7XciEW26pVIiqVaTAqleGxapUNgiIioqquuJ/fFaJiNXr0aPTv3x+9evVStMfHxyMlJQV9+vQxtqnVaoSEhGDPnj0AgIMHDyInJ0fRR6vVIigoyNgnNjYWGo0GHTp0MPbp2LEjNBqNok9QUBC0BVbG7Nu3L7KysnDw4MEiY8/KykJ6erriYVEWqO48/TQQFKRsy8gwDAlalV4PjBtnfiJXfltkJIcFiYjIbtl9YhUVFYVDhw5h2rRpJttSUlIAAL6+vop2X19f47aUlBQ4OzvDq9DaAIX7+BS+izAAHx8fRZ/Cx/Hy8oKzs7OxjznTpk0zztvSaDQICAh40CkXX3Q0MHgwUGi+GJKSDO0PSK5EDEN/a9bca3NwMLS7uVkuzGLbtcv0XAoSARITDf2IiIjskF0nVomJiRg3bhx+/PFHuLi4FNlPVejyNRExaSuscB9z/UvTp7BJkyZBp9MZH4mJifeNq9jKWN05dMiQRBW0YoWNi0HJyZbtR0REZGV2nVgdPHgQV69eRbt27VCtWjVUq1YNO3bswNdff41q1aoZK0iFK0ZXr141bvPz80N2djbS0tLu2+fKlSsmx7927ZqiT+HjpKWlIScnx6SSVZBarYanp6fiYRFlqO706gW0a6dsy8wEnnvOMqGVWp06lu1HRERkZXadWPXs2RPHjh1DXFyc8dG+fXuMGDECcXFxaNiwIfz8/LBlyxbja7Kzs7Fjxw507twZANCuXTs4OTkp+iQnJ+P48ePGPp06dYJOp8P+/fuNffbt2wedTqfoc/z4cSQXqJZs3rwZarUa7QpnKdZQiupO/tDf1q33Nnt7G9rVagvHVxrBwYZ7BxZVAVSpgIAAQz8iIiI7ZNcrr3t4eCCo0Kxqd3d31KxZ09geGRmJzz77DE2aNEGTJk3w2Wefwc3NDcOHDwcAaDQa/OMf/8CECRNQs2ZNeHt746233kLLli2Nk+GbN2+Ofv364ZVXXsE333wDAHj11VcRGhqKpk2bAgD69OmDFi1aIDw8HDNnzsSNGzfw1ltv4ZVXXrFcFaokSljdSUwE6tVTblq3DggNtXBcZeHoCMyZY5gfplIphznzk63Zsw39iIiI7JEVrlC0qILLLYgYllyYPHmy+Pn5iVqtlq5du8qxY8cUr7l7965ERESIt7e3uLq6SmhoqCQkJCj6pKamyogRI8TDw0M8PDxkxIgRkpaWpuhz8eJF6d+/v7i6uoq3t7dERERIZmZmieK32HILubki/v7mlybIX54gIEAkN1cWLTLdnJ1dtsOXq1WrDOdWMOCAAC61QERENlPcz2+VCG9SYk3p6enQaDTQ6XRlr3TlXxUImK3uyC8r0XRSGM6cubdp9mzDnHe7p9cb5oclJxuqbsHBrFQREZHNFPfz266HAukBwsKAlSsNmVLBiez+/oiftAgNB/dTdD93DmjY0MoxlpajI9Ctm62jICIiKhEmVhVdWBgwcKCiujP3SFeM/ee96xIaNwb++st0eQUiIiKyLCZWlcHf1Z28PKB+fWXxasEC4PXXbRcaERFRVcLEqpI4cwZ46CFl28WLplcCEhERUfnh4FAlUTCpatUKyMtjUkVERGRtTKwqifwbJn//PXDkSNFrbBIREVH54XILVmbR5RaIiIjIKor7+c2KFREREZGFMLEiIiIishAmVkREREQWwsSKiIiIyEKYWBERERFZCBMrIiIiIgthYkVERERkIUysiIiIiCyEiRURERGRhTCxIiIiIrIQJlZEREREFsLEioiIiMhCmFgRERERWQgTKyIiIiILqWbrAKoaEQEApKen2zgSIiIiKq78z+38z/GiMLGyslu3bgEAAgICbBwJERERldStW7eg0WiK3K6SB6VeZFF5eXm4fPkyPDw8oFKpbB2OTaSnpyMgIACJiYnw9PS0dThVDt9/2+L7b1t8/22rIr//IoJbt25Bq9XCwaHomVSsWFmZg4MD/P39bR2GXfD09Kxwv1iVCd9/2+L7b1t8/22ror7/96tU5ePkdSIiIiILYWJFREREZCFMrMjq1Go1Jk+eDLVabetQqiS+/7bF99+2+P7bVlV4/zl5nYiIiMhCWLEiIiIishAmVkREREQWwsSKiIiIyEKYWBERERFZCBMrsppp06bh0UcfhYeHB3x8fDBo0CD89ddftg6rSpo2bRpUKhUiIyNtHUqVkpSUhOeffx41a9aEm5sbWrdujYMHD9o6rCohNzcX77//Pho0aABXV1c0bNgQH330EfLy8mwdWqW0c+dODBgwAFqtFiqVCmvWrFFsFxFMmTIFWq0Wrq6u6NatG06cOGGbYC2MiRVZzY4dOzB69Gjs3bsXW7ZsQW5uLvr06YOMjAxbh1alHDhwAIsWLUKrVq1sHUqVkpaWhscffxxOTk749ddfcfLkSXz55ZeoUaOGrUOrEqZPn46FCxdi3rx5OHXqFGbMmIGZM2di7ty5tg6tUsrIyMAjjzyCefPmmd0+Y8YMzJo1C/PmzcOBAwfg5+eH3r17G++nW5FxuQWymWvXrsHHxwc7duxA165dbR1OlXD79m20bdsW8+fPxyeffILWrVtj9uzZtg6rSnj33Xfx+++/Y9euXbYOpUoKDQ2Fr68vFi9ebGx75pln4ObmhqVLl9owsspPpVJh9erVGDRoEABDtUqr1SIyMhITJ04EAGRlZcHX1xfTp0/Ha6+9ZsNoy44VK7IZnU4HAPD29rZxJFXH6NGj0b9/f/Tq1cvWoVQ5a9euRfv27fHss8/Cx8cHbdq0wbfffmvrsKqMLl26YOvWrTh9+jQA4MiRI9i9ezeefPJJG0dW9cTHxyMlJQV9+vQxtqnVaoSEhGDPnj02jMwyeBNmsgkRwfjx49GlSxcEBQXZOpwqISoqCocOHcKBAwdsHUqVdP78eSxYsADjx4/Hv/71L+zfvx9jx46FWq3GCy+8YOvwKr2JEydCp9OhWbNmcHR0hF6vx6effophw4bZOrQqJyUlBQDg6+uraPf19cXFixdtEZJFMbEim4iIiMDRo0exe/duW4dSJSQmJmLcuHHYvHkzXFxcbB1OlZSXl4f27dvjs88+AwC0adMGJ06cwIIFC5hYWcGKFSvw448/YtmyZXj44YcRFxeHyMhIaLVajBw50tbhVUkqlUrxXERM2ioiJlZkdWPGjMHatWuxc+dO+Pv72zqcKuHgwYO4evUq2rVrZ2zT6/XYuXMn5s2bh6ysLDg6OtowwsqvTp06aNGihaKtefPmWLVqlY0iqlrefvttvPvuuxg6dCgAoGXLlrh48SKmTZvGxMrK/Pz8ABgqV3Xq1DG2X7161aSKVRFxjhVZjYggIiIC0dHR2LZtGxo0aGDrkKqMnj174tixY4iLizM+2rdvjxEjRiAuLo5JlRU8/vjjJsuLnD59GvXr17dRRFXLnTt34OCg/MhzdHTkcgs20KBBA/j5+WHLli3GtuzsbOzYsQOdO3e2YWSWwYoVWc3o0aOxbNky/O9//4OHh4dxnF2j0cDV1dXG0VVuHh4eJnPZ3N3dUbNmTc5xs5I333wTnTt3xmeffYbnnnsO+/fvx6JFi7Bo0SJbh1YlDBgwAJ9++inq1auHhx9+GIcPH8asWbPw0ksv2Tq0Sun27ds4e/as8Xl8fDzi4uLg7e2NevXqITIyEp999hmaNGmCJk2a4LPPPoObmxuGDx9uw6gtRIisBIDZx/fff2/r0KqkkJAQGTdunK3DqFLWrVsnQUFBolarpVmzZrJo0SJbh1RlpKeny7hx46RevXri4uIiDRs2lPfee0+ysrJsHVqlFBMTY/bv/ciRI0VEJC8vTyZPnix+fn6iVqula9eucuzYMdsGbSFcx4qIiIjIQjjHioiIiMhCmFgRERERWQgTKyIiIiILYWJFREREZCFMrIiIiIgshIkVERERkYUwsSIiIiKyECZWREQA1qxZg8aNG8PR0RGRkZG2DqdUAgMDMXv2bFuHQVSlMbEiolITEfTq1Qt9+/Y12TZ//nxoNBokJCTYILKSe+211zB48GAkJibi448/NtsnMDAQKpXK5PH5559bOVrzDhw4gFdffdXWYRBVaVx5nYjKJDExES1btsT06dPx2muvATDcF6xVq1aYO3cuRo0aZdHj5eTkwMnJyaL7vH37Njw8PLBt2zZ07969yH6BgYH4xz/+gVdeeUXR7uHhAXd3d4vGVBLZ2dlwdna22fGJ6B5WrIioTAICAjBnzhy89dZbiI+Ph4jgH//4B3r27InHHnsMTz75JKpXrw5fX1+Eh4fj+vXrxtdu3LgRXbp0QY0aNVCzZk2Ehobi3Llzxu0XLlyASqXCzz//jG7dusHFxQU//vgjLl68iAEDBsDLywvu7u54+OGHsWHDhiJjTEtLwwsvvAAvLy+4ubnhiSeewJkzZwAA27dvh4eHBwCgR48eUKlU2L59e5H78vDwgJ+fn+KRn1R99NFH0Gq1SE1NNfZ/6qmn0LVrV+Tl5QEAVCoVFixYgCeeeAKurq5o0KABfvnlF8UxkpKSMGTIEHh5eaFmzZoYOHAgLly4YNw+atQoDBo0CNOmTYNWq8VDDz0EwHQoUKfT4dVXX4WPjw88PT3Ro0cPHDlyxLh9ypQpaN26NZYuXYrAwEBoNBoMHToUt27dMvbJy8vD9OnT0bhxY6jVatSrVw+ffvppsWMlqmqYWBFRmY0cORI9e/bEiy++iHnz5uH48eOYM2cOQkJC0Lp1a/zxxx/YuHEjrly5gueee874uoyMDIwfPx4HDhzA1q1b4eDggKefftqYhOSbOHEixo4di1OnTqFv374YPXo0srKysHPnThw7dgzTp09H9erVi4xv1KhR+OOPP7B27VrExsZCRPDkk08iJycHnTt3xl9//QUAWLVqFZKTk9G5c+dSvQ/vvfceAgMD8fLLLwMAFi5ciJ07d2Lp0qVwcLj35/aDDz7AM888gyNHjuD555/HsGHDcOrUKQDAnTt30L17d1SvXh07d+7E7t27Ub16dfTr1w/Z2dnGfWzduhWnTp3Cli1bsH79epNYRAT9+/dHSkoKNmzYgIMHD6Jt27bo2bMnbty4Yex37tw5rFmzBuvXr8f69euxY8cOxdDmpEmTMH36dHzwwQc4efIkli1bBl9f3xLFSlSl2O7+z0RUmVy5ckVq164tDg4OEh0dLR988IH06dNH0ScxMVEAyF9//WV2H1evXhUAxrvcx8fHCwCZPXu2ol/Lli1lypQpxYrr9OnTAkB+//13Y9v169fF1dVVfv75ZxERSUtLEwASExNz333Vr19fnJ2dxd3dXfEo+Lpz586Jh4eHTJw4Udzc3OTHH39U7AOAvP7664q2Dh06yBtvvCEiIosXL5amTZtKXl6ecXtWVpa4urrKpk2bRERk5MiR4uvrK1lZWSbxffXVVyIisnXrVvH09JTMzExFn0aNGsk333wjIiKTJ08WNzc3SU9PN25/++23pUOHDiIikp6eLmq1Wr799luz70dxYiWqaqrZMqkjosrDx8cHr776KtasWYOnn34a3333HWJiYsxWks6dO4eHHnoI586dwwcffIC9e/fi+vXrxkpVQkICgoKCjP3bt2+veP3YsWPxxhtvYPPmzejVqxeeeeYZtGrVymxcp06dQrVq1dChQwdjW82aNdG0aVNjlagk3n77bZN5Y3Xr1jX+u2HDhvjiiy/w2muvYciQIRgxYoTJPjp16mTyPC4uDgBw8OBBnD171jg8mS8zM1MxTNqyZcv7zqs6ePAgbt++jZo1ayra7969q9hPYGCg4lh16tTB1atXARjeu6ysLPTs2bPIYxQnVqKqhIkVEVlMtWrVUK2a4c9KXl4eBgwYgOnTp5v0q1OnDgBgwIABCAgIwLfffgutVou8vDwEBQWZDCMVnhj+8ssvo2/fvvi///s/bN68GdOmTcOXX36JMWPGmBxLirg+R0SgUqlKfI61atVC48aN79tn586dcHR0xIULF5Cbm2t8T+4nP5a8vDy0a9cOP/30k0mf2rVrG//9oMnyeXl5qFOnjtn5YjVq1DD+u/CFACqVypjgurq6PvAYxYmVqCrhHCsiKhdt27bFiRMnEBgYiMaNGyse7u7uSE1NxalTp/D++++jZ8+eaN68OdLS0oq9/4CAALz++uuIjo7GhAkT8O2335rt16JFC+Tm5mLfvn3GttTUVJw+fRrNmzcv83kWtmLFCkRHR2P79u1FLt2wd+9ek+fNmjUDYHjfzpw5Ax8fH5P3TaPRFDuOtm3bIiUlBdWqVTPZT61atYq1jyZNmsDV1RVbt24t8hiWiJWoMmFiRUTlYvTo0bhx4waGDRuG/fv34/z589i8eTNeeukl6PV641VkixYtwtmzZ7Ft2zaMHz++WPuOjIzEpk2bEB8fj0OHDmHbtm1FJklNmjTBwIED8corr2D37t3GCeN169bFwIEDS3xet27dQkpKiuKRnp4OALh06RLeeOMNTJ8+HV26dMF///tfTJs2zSSR+uWXX/Cf//wHp0+fxuTJk7F//35EREQAAEaMGIFatWph4MCB2LVrF+Lj47Fjxw6MGzcOly5dKnacvXr1QqdOnTBo0CBs2rQJFy5cwJ49e/D+++/jjz/+KNY+XFxcMHHiRLzzzjtYsmQJzp07h71792Lx4sUWjZWoMmFiRUTlQqvV4vfff4der0ffvn0RFBSEcePGQaPRwMHBAQ4ODoiKisLBgwcRFBSEN998EzNnzizWvvV6PUaPHo3mzZujX79+aNq0KebPn19k/++//x7t2rVDaGgoOnXqBBHBhg0bSrUe1ocffog6deooHu+88w5EBKNGjcJjjz1mTJJ69+6NiIgIPP/887h9+7ZxH1OnTkVUVBRatWqFH374AT/99BNatGgBAHBzc8POnTtRr149hIWFoXnz5njppZdw9+5deHp6FjtOlUqFDRs2oGvXrnjppZfw0EMPYejQobhw4YLxqr7i+OCDDzBhwgR8+OGHaN68OYYMGWKcg2WpWIkqEy4QSkRkRSqVCqtXr8agQYNsHQoRlQNWrIiIiIgshIkVERERkYVwuQUiIivi7Auiyo0VKyIiIiILYWJFREREZCFMrIiIiIgshIkVERERkYUwsSIiIiKyECZWRERERBbCxIqIiIjIQphYEREREVkIEysiIiIiC/l/4SdiAc2t3uIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_test = real salaries given to us in the data table \n",
    "# y_pred_test = predicted salaries of the test set \n",
    "# y_pred_train = predicted salaries of the training set \n",
    "\n",
    "#VISUALISING THE TRAINING SET RESULTS \n",
    "plt.scatter(X_train, y_train, color = 'red') #scatter plot representing all the points of the training set \n",
    "plt.plot(X_train, y_pred_train, color = 'blue') \n",
    "plt.title('Experience based Salaries(Training set)') #title of the plot \n",
    "plt.xlabel('Years of Experience') #label to the x-axis \n",
    "plt.ylabel('Salaries') #label to the y-axis \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c7c64ac-d2fe-4a99-b755-e780b7a28d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VISUALISING THE TEST SET RESULTS \n",
    "plt.scatter(X_test, y_test, color = 'red') #scatter plot representing all the points of the test set \n",
    "plt.plot(X_train, y_pred_train, color = 'blue')   # regression line should be same so same line of code as above \n",
    "plt.title('Experience based Salaries(Test set)')  \n",
    "plt.xlabel('Years of Experience') \n",
    "plt.ylabel('Salaries') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0b7eb-1aec-45e9-88a3-b3c1eae36e90",
   "metadata": {},
   "source": [
    "Key modifications: had to reshape X to 2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa961cfb-cd26-4378-85ce-2ebe1b25564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138531.00067138]\n"
     ]
    }
   ],
   "source": [
    "# Q1.) making a single prediction (for example the salary of an employee with 12 years of experience? )\n",
    "print(regressor.predict([[12]])) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b02d75b4-a955-467f-9c28-5928d42708ae",
   "metadata": {},
   "source": [
    "important note: Notice that the value of the feature (12 years) was input in a double pair of square brackets thats because the predict method always expects a 2D array as the format of its inputs \n",
    "12 -> scalar \n",
    "[12] -> 1D array \n",
    "[[12]] -> 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e0d225-39f5-450e-a386-d8fd2524d3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9312.57512673]\n",
      "26780.099150628157\n"
     ]
    }
   ],
   "source": [
    "# Q2.) Getting the final linnear regression equation with the values of the coefficient \n",
    "print(regressor.coef_)\n",
    "print(regressor.intercept_)\n",
    "\n",
    "# the eqtion of the linear regression model is salary = (regressor.coef_) * YearsExperience + (regressor_intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86c37410-fad6-4cbc-a402-0c9e85b02a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salary = 9312.57 * YearsExperience + 26780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97807d9-83f5-42cb-b886-14547214b847",
   "metadata": {},
   "source": [
    "## MULTI-LINEAR REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13197bac-ffaa-4c28-a771-f6d31639652f",
   "metadata": {},
   "source": [
    "### Assumptions of Multi -linear regression models "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8928811e-f5e2-43c8-bd7a-b18ec3f53d4c",
   "metadata": {},
   "source": [
    "1. Linearity = linear relationship between y and each X \n",
    "2. Homoscedasticity = equal variance \n",
    "3. Multivariate normality = Normality of error distribution \n",
    "4. Independence = of observation, \"includes  no autocorrelation \" \n",
    "5. Lack of Multicollinearity = Predictors(X's) are not correlated with each other \n",
    "6. Outlier check = based on the buisness knwledge or the dataset knowledge you can choose if you want to keep the outlier or remove it before using linear regression "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3706c655-d411-4c34-a1b0-dd2e7410fa0e",
   "metadata": {},
   "source": [
    "y = β0 +β1 x1 +β2 x2 + ⋯ +βp xp + ϵ\n",
    "\n",
    "where, \n",
    "y = dependent variable( target/ output) \n",
    "β0 = intercept (the value of y when all xi = 0 )\n",
    "x1, x2,... xp = independent variables( features/predictors) \n",
    "β1, β2.. βp = coefficients of the independent variables (weights showing the impact of each predictor on y) \n",
    "ϵ = Error term (captures the variablitiy in y not explained by the predictors) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d2c9e-6c76-4968-9fce-4825f03ff27d",
   "metadata": {},
   "source": [
    "Goal: The Goal of the MLR is to find the values of β1, β2.. βp that minimise the sum of square of residuals(SSE) ; typically achieved using OLS {same as Simple linear regression} \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfe8e7a3-a6b7-43cc-84fe-7c3c0379544e",
   "metadata": {},
   "source": [
    "DATA: Independent variables/predictors (X1, X2, X3 X4) = R&D spend ; Administration ; Marketing spend ; State \n",
    "Dependent variable / response / outcome (y) = Profit\n",
    "\n",
    "Question: they want to perform an analyse based on the independent variables to identify which company has good amount profits inorder to decide which company to invest in ? (not just based on the company with maximum profit but analyse for example if a company based on california, that spends less on R&D and more on marketing has better results thann company based in Newyork that spends equally on R&D and Marketting)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc7f011c-5852-40ba-b22c-af19601d3bd0",
   "metadata": {},
   "source": [
    "Now we have a column in the dataset 'State' where the data is categorical \n",
    "DUMMY VARIABLE \n",
    "1. In this case look for the number of categories in the column (Neywork , California) \n",
    "2.DUMMY VARIABLES: (basically you will now be creating 2 columns Newyork, California) and { under the Neywork coulmn if its from Newyork 1 rest 0 } similarly {for California, if its from california 1 rest 0} \n",
    "3. eqtn: y = β0 +β1 x1 +β2 x2 +β3 x3 + β4 D1 \n",
    "\n",
    "where, \n",
    "D1 = dummy variable {newyork} \n",
    "\n",
    "Dummy variable trap : You dnt include both the dummy variables in the equation since its quite obvious even from 1 dummy variable input that if its from Neywork its not from California \n",
    "similarly if its from California its not from newyork : ADDING BOTH THE DUMMY VARIABLES IS JUST GOING TO CREATE A DUPLICATE UNNECESSARY INPUT \n",
    "\n",
    "D2 = 1 - D1      OR        D1 = 1 - D2 \n",
    "\n",
    "Note: if you have 100 dummy variables only include 99 , if 5 only include 4 ..... "
   ]
  },
  {
   "cell_type": "raw",
   "id": "610ee290-d06d-4df1-8857-20f6eb2d15f2",
   "metadata": {},
   "source": [
    "THEORY: \n",
    "\n",
    "Q. Tossing a fair coin example \n",
    "Hypothesis testing: \n",
    "\n",
    "(Null hypothesis) H0: This is a fair coin \n",
    "(alternative hypothesis) H1: This is not a fair coin \n",
    "α = statistical significance (usually 0.05) \n",
    "\n",
    "5 METHODS OF BUILDING A MODEL:  \n",
    "1. All-in <-- you use all the varibales \n",
    "\n",
    "2. Backward Elimination <--  you need all-in for this \n",
    "\n",
    "       step 1: select a significance level to stay in the model, α = 0.05 \n",
    "       step 2: fit the full model with all possible predictors \n",
    "       step 3: Consider the predictor with the highest p-value if P > α, go to step 4 or go to FINISH\n",
    "       step 4: Remove that predictor \n",
    "       step 5: Fit the model without this variable \n",
    "       step 6: Go back to step 3, repeat until P < α if so FINISH \n",
    "\n",
    "3. Forward selection \n",
    "\n",
    "       step 1: select a significance level to stay in the model α = 0.05 \n",
    "       step 2: we fit all possible simple regression models( like model with each predictor = response combination)  Y ~ Xn , select the one with the lowest P-value \n",
    "       step 3: So now we have selected the simple regression model we are going to use , now we add (only 1) other permutation of predictor with the equation to check with combination \n",
    "       step 4: consider the predictor with the lowest P-value if P < α go to step 3 else FIN \n",
    "       \n",
    "       so basically we will keep growing the regression model but not just randomly we will actually be selecting out of all of the possible cmbination every single time and growing at          one variable at a time \n",
    "       \n",
    "       step 5: when P > α , stop \n",
    "       step 6: you dont keep the current model , you keep the previous one  \n",
    " \n",
    "\n",
    "4. Bidirectional elimination (can be replaced with 'stepwise regression') \n",
    "       step 1: select a significance level to stay(SLSTAY) = 0.05 and to enter(SLENTER) = 0.05 the model \n",
    "       step 2: perform the next step of the forward selection (new variable must have P < SLENTER to enter) \n",
    "       step 3: perform all of the steps of the backward elimination technique (old variable must have P < SLSTAY to stay) \n",
    "       step 4: at some point no new variables will be able to enter and no old variables can exit that when u FINISH \n",
    "\n",
    "5. Score comparison \n",
    "       step 1: you select a criterion for goodness of fit (eg:Akaike criterion)\n",
    "       step 2: construct all possible regression models: (2^N)-1 total cmbinations \n",
    "       step 3: select the one with the best criterion \n",
    "       step 4: FIN \n",
    "       EG : if you have 10 columns you will have 1023 models \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c4b858-2d98-4592-b0bf-8f7f2c95fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "#dataloading \n",
    "dataset = pd.read_csv('MultiLinear_data.csv') \n",
    "X = dataset.iloc[:,:4].values \n",
    "y = dataset.iloc[:,4].values \n",
    "\n",
    "#handeling categorical data \n",
    "ct = ColumnTransformer(transformers = [('encoder',OneHotEncoder(),[3])],remainder='passthrough') \n",
    "X = np.array(ct.fit_transform(X))\n",
    "#print(X) \n",
    "\n",
    "#spliting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea4365-49fe-4e02-8eb7-b8ec08043dfe",
   "metadata": {},
   "source": [
    "#### backward elimination \n",
    "#### IN MULTIPLE LINEAR REGRESSION THERE IS ABSOLUTELY NO NEED TO APPLY FEATURE SCALING as the features get multiplied with the coefficients 'β..' as it is\n",
    "- you dont have to worry about the dummy variable trap here the class handels it automatically\n",
    "- you dont have to manually do all the steps of backward elimination as well the class we call frm the scikit learn library already has a code for handling this \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701da068-ac9d-4be6-8652-80dc8b3ea183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the multi-linear regression model on the training set \n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8ef248-26ab-4a2b-8195-70966a660cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the test set \n",
    "y_pred_test = regressor.predict(X_test) \n",
    "\n",
    "#displaying the output for comparison \n",
    "np.set_printoptions(precision =2)    #this will display any numerical value with only two decimals after comma \n",
    "print(np.concatenate((y_pred_test.reshape(len(y_pred_test),1),y_test.reshape(len(y_test),1)),1 ))  #.reshape-- to display the two vectors vertically into a array having y_pred_test number of rows , and just 1 column \n",
    "#1st argument of concatenate fun= y_pred_test.reshape(len(y_pred_test),1),y_test.reshape(len(y_test),1)\n",
    "#2nd argument axis: 0 = vertical concatenation ; 1 = horizontal concatenation \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08024a5d-01a9-4c5d-83b9-7952dd26eaac",
   "metadata": {},
   "source": [
    "[[vector of predicted profits    vector of actual profits ]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1cc9796-d37f-4954-a231-4d5e63ed8f97",
   "metadata": {},
   "source": [
    "Backward Elimination(model tuning) is irrelevant in Python, because the Scikit-Learn library automatically takes care of selecting the statistically significant features when training the model to make accurate predictions.\n",
    "#Just for learning purposes I have manually implemented backward elimination \n",
    "\n",
    "observe: \n",
    "eqtn: y = β0 +β1 x1 +β2 x2 +β3 x3 + β4 D1  \n",
    "β0 --> has no x0 , but we can consider there is a x0 which is equal to 1 right ? \n",
    "the stats model library does not take into account β0 constant , but it needs to be included right ? so we consider x0 =1 and we add a column of 1's in the data as x0 values to include in the matrix of features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3c0b4dc-d90b-401b-9c50-9718633829d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for Backward elimination \n",
    "data = pd.read_csv(\"MultiLinear_data.csv\")\n",
    "X = data.iloc[:,:4].values \n",
    "y = data.iloc[:,4].values\n",
    "\n",
    "#handeling categorical data \n",
    "ct = ColumnTransformer(transformers = [('encoder',OneHotEncoder(),[3])],remainder='passthrough') \n",
    "X = np.array(ct.fit_transform(X))\n",
    "#print(X) \n",
    "\n",
    "#avoiding the dummy variable trap \n",
    "X =X[:,1:]\n",
    "\n",
    "#spliting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0) \n",
    "\n",
    "#fitting the linear regressor \n",
    "regressor = LinearRegression() \n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "#predicting the test set \n",
    "y_pred = regressor.predict(X_test) \n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    " \n",
    "X = np.append(arr=np.ones((50,1)).astype(int) , values = X ,axis =1)\n",
    "#print(X)\n",
    "#arr = array of 50 lines of 1's --> shortcut to do this np.ones((shape= 50 rows, 1 col).datatype, value = dataset where we want the column added, axis =1 ) #if line : axis = 0 , clumn : axis = 1 \n",
    "#append adds column to the end of the set , hence I have interchanged the value of arr and values so that the new col will be at the begining of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638763fe-1fa2-4c48-9a6e-07c9f240269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:48:03</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     169.9   \\\\\n",
       "\\textbf{Date:}             & Fri, 10 Jan 2025 & \\textbf{  Prob (F-statistic):} &  1.34e-27   \\\\\n",
       "\\textbf{Time:}             &     20:48:03     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Residuals:}     &          44      & \\textbf{  BIC:               } &     1074.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.013e+04  &     6884.820     &     7.281  &         0.000        &     3.62e+04    &      6.4e+04     \\\\\n",
       "\\textbf{x1}    &     198.7888  &     3371.007     &     0.059  &         0.953        &    -6595.030    &     6992.607     \\\\\n",
       "\\textbf{x2}    &     -41.8870  &     3256.039     &    -0.013  &         0.990        &    -6604.003    &     6520.229     \\\\\n",
       "\\textbf{x3}    &       0.8060  &        0.046     &    17.369  &         0.000        &        0.712    &        0.900     \\\\\n",
       "\\textbf{x4}    &      -0.0270  &        0.052     &    -0.517  &         0.608        &       -0.132    &        0.078     \\\\\n",
       "\\textbf{x5}    &       0.0270  &        0.017     &     1.574  &         0.123        &       -0.008    &        0.062     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.782 & \\textbf{  Durbin-Watson:     } &    1.283  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.266  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.41e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.572 & \\textbf{  Cond. No.          } & 1.45e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.45e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Fri, 10 Jan 2025   Prob (F-statistic):           1.34e-27\n",
       "Time:                        20:48:03   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the model using backward elimination \n",
    "\n",
    "#Step 2: fit the full model with all possible  predictors \n",
    "X_opt = X[:,[0,1,2,3,4,5]].astype(float) #new matrix of features, will only cntain features that contribute the most at the end \n",
    "#we write all the columns to be included individually as they will be removed one by one depending n thier contribution to prediction \n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y, exog = X_opt).fit()  #endog = dependent variable , exog = matrix of features(X_opt) , fit() = fits OLS to X_opt and y \n",
    "\n",
    "#Step 3: Consider the predictor with the highest P-value . If P > SL , go to STEP 4 otherwise go to FIN \n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18990be0-48c4-4498-a397-ca4ce1eb8bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:02:19</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     217.2   \\\\\n",
       "\\textbf{Date:}             & Fri, 10 Jan 2025 & \\textbf{  Prob (F-statistic):} &  8.49e-29   \\\\\n",
       "\\textbf{Time:}             &     21:02:19     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1061.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &     1070.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.011e+04  &     6647.870     &     7.537  &         0.000        &     3.67e+04    &     6.35e+04     \\\\\n",
       "\\textbf{x1}    &     220.1585  &     2900.536     &     0.076  &         0.940        &    -5621.821    &     6062.138     \\\\\n",
       "\\textbf{x2}    &       0.8060  &        0.046     &    17.606  &         0.000        &        0.714    &        0.898     \\\\\n",
       "\\textbf{x3}    &      -0.0270  &        0.052     &    -0.523  &         0.604        &       -0.131    &        0.077     \\\\\n",
       "\\textbf{x4}    &       0.0270  &        0.017     &     1.592  &         0.118        &       -0.007    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.758 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.172  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.53e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.563 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Fri, 10 Jan 2025   Prob (F-statistic):           8.49e-29\n",
       "Time:                        21:02:19   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,3,4,5]].astype(float) #new matrix of features, will only cntain features that contribute the most at the end \n",
    "#we write all the columns to be included individually as they will be removed one by one depending n thier contribution to prediction \n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y, exog = X_opt).fit()  #endog = dependent variable , exog = matrix of features(X_opt) , fit() = fits OLS to X_opt and y \n",
    "\n",
    "#Step 3: Consider the predictor with the highest P-value . If P > SL , go to STEP 4 otherwise go to FIN \n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "432faff3-f27d-4b2a-863c-261285e385fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:05:28</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     296.0   \\\\\n",
       "\\textbf{Date:}             & Fri, 10 Jan 2025 & \\textbf{  Prob (F-statistic):} &  4.53e-30   \\\\\n",
       "\\textbf{Time:}             &     21:05:28     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          46      & \\textbf{  BIC:               } &     1066.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.012e+04  &     6572.353     &     7.626  &         0.000        &     3.69e+04    &     6.34e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.045     &    17.846  &         0.000        &        0.715    &        0.897     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.051     &    -0.526  &         0.602        &       -0.130    &        0.076     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.016     &     1.655  &         0.105        &       -0.006    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.838 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.442  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.21e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.586 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Fri, 10 Jan 2025   Prob (F-statistic):           4.53e-30\n",
       "Time:                        21:05:28   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3,4,5]].astype(float) #new matrix of features, will only cntain features that contribute the most at the end \n",
    "#we write all the columns to be included individually as they will be removed one by one depending n thier contribution to prediction \n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y, exog = X_opt).fit()  #endog = dependent variable , exog = matrix of features(X_opt) , fit() = fits OLS to X_opt and y \n",
    "\n",
    "#Step 3: Consider the predictor with the highest P-value . If P > SL , go to STEP 4 otherwise go to FIN \n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c0f2f95-c767-41d9-b6fe-9cd103f49987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:31</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & Fri, 10 Jan 2025 & \\textbf{  Prob (F-statistic):} &  2.16e-31   \\\\\n",
       "\\textbf{Time:}             &     21:07:31     & \\textbf{  Log-Likelihood:    } &   -525.54   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1057.   \\\\\n",
       "\\textbf{Df Residuals:}     &          47      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.698e+04  &     2689.933     &    17.464  &         0.000        &     4.16e+04    &     5.24e+04     \\\\\n",
       "\\textbf{x1}    &       0.7966  &        0.041     &    19.266  &         0.000        &        0.713    &        0.880     \\\\\n",
       "\\textbf{x2}    &       0.0299  &        0.016     &     1.927  &         0.060        &       -0.001    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.677 & \\textbf{  Durbin-Watson:     } &    1.257  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.161  \\\\\n",
       "\\textbf{Skew:}          & -0.939 & \\textbf{  Prob(JB):          } & 2.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.575 & \\textbf{  Cond. No.          } & 5.32e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.32e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Fri, 10 Jan 2025   Prob (F-statistic):           2.16e-31\n",
       "Time:                        21:07:31   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3,5]].astype(float) #new matrix of features, will only cntain features that contribute the most at the end \n",
    "#we write all the columns to be included individually as they will be removed one by one depending n thier contribution to prediction \n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y, exog = X_opt).fit()  #endog = dependent variable , exog = matrix of features(X_opt) , fit() = fits OLS to X_opt and y \n",
    "\n",
    "#Step 3: Consider the predictor with the highest P-value . If P > SL , go to STEP 4 otherwise go to FIN \n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52251dc5-9f52-4465-8b74-5ce9ac2acb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:08:11</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.947   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     849.8   \\\\\n",
       "\\textbf{Date:}             & Fri, 10 Jan 2025 & \\textbf{  Prob (F-statistic):} &  3.50e-32   \\\\\n",
       "\\textbf{Time:}             &     21:08:11     & \\textbf{  Log-Likelihood:    } &   -527.44   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.903e+04  &     2537.897     &    19.320  &         0.000        &     4.39e+04    &     5.41e+04     \\\\\n",
       "\\textbf{x1}    &       0.8543  &        0.029     &    29.151  &         0.000        &        0.795    &        0.913     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 13.727 & \\textbf{  Durbin-Watson:     } &    1.116  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   18.536  \\\\\n",
       "\\textbf{Skew:}          & -0.911 & \\textbf{  Prob(JB):          } & 9.44e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.361 & \\textbf{  Cond. No.          } & 1.65e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.65e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Fri, 10 Jan 2025   Prob (F-statistic):           3.50e-32\n",
       "Time:                        21:08:11   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3]].astype(float) #new matrix of features, will only cntain features that contribute the most at the end \n",
    "#we write all the columns to be included individually as they will be removed one by one depending n thier contribution to prediction \n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y, exog = X_opt).fit()  #endog = dependent variable , exog = matrix of features(X_opt) , fit() = fits OLS to X_opt and y \n",
    "\n",
    "#Step 3: Consider the predictor with the highest P-value . If P > SL , go to STEP 4 otherwise go to FIN \n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef21bcf-2498-4ab3-a0ad-588cb7269cc2",
   "metadata": {},
   "source": [
    "## POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbd947d8-5421-480d-b46e-5c26c755d64f",
   "metadata": {},
   "source": [
    "Non-Linear data \n",
    "y = b0 + b1x1 + b2(x1)^2 + ...bn(x1)^n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbbde7-de5b-4cff-bf49-925c616ae80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "79b5463c-d895-4870-ac4a-867c790315dd"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
